{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "import os\n",
      "import pyTools.videoProc.annotation as annotation\n",
      "import pyTools.misc.config as cfg\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataFolder = '/run/media/peter/Elements/peter/data/tmp-20130506'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "behaviour = \"struggling\"\n",
      "annotator = \"peter\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractAnnotatedFrames(vials=None, annotator=\"peter\", behaviour=\"struggling\", \n",
      "                           dataFolder='/run/media/peter/Elements/peter/data/tmp-20130506'):\n",
      "    \n",
      "    filt = annotation.AnnotationFilter(vials, [annotator], [behaviour])\n",
      "    frames = []\n",
      "    \n",
      "    # list of filtered frames (one list for each vial)\n",
      "    a = [[] for i in range(4)]\n",
      "    \n",
      "    for root, dirs, files in os.walk(dataFolder):\n",
      "        for file in files:\n",
      "            if file.endswith(\".bhvr\"):\n",
      "                # load annotation and filter it #\n",
      "                path = os.path.join(root,file)\n",
      "                anno = annotation.Annotation()\n",
      "        \n",
      "                anno.loadFromFile(path)\n",
      "                filteredAnno = anno.filterFrameList(filt)\n",
      "                \n",
      "                if behaviour in anno.behaviours and annotator in anno.annotators:\n",
      "                    # extract frame numbers corresponding to filter #\n",
      "                    frameList = [[i, x] for i, x in enumerate(filteredAnno.frameList)  \\\n",
      "                                             if x is not None]\n",
      "                    \n",
      "                    # sort frames into the different vials to know what\n",
      "                    # feature files we will have to load later #\n",
      "                    if frameList:\n",
      "                        for f in frameList:\n",
      "                            frames += [[path, f[0]]]\n",
      "                            for v in range(len(a)):\n",
      "                                if f[1][v] is not None:\n",
      "                                    a[v] += [[path, f[0]]]\n",
      "                    \n",
      "    return a\n",
      "                    \n",
      "\n",
      "       \n",
      "# cfg.log.info(\"finished in {0} sec\".format(time.time() - t))   \n",
      "\n",
      "def createFeatureVector(a, ending=['feat.hog3d']):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        a (list [[path, int]]):\n",
      "                    list of paths with corresponding\n",
      "                    frame numbers\n",
      "                    see :func:`extractAnnotatedFrames`\n",
      "    \"\"\"\n",
      "    # feature matrix #\n",
      "    feats = []\n",
      "    for i in range(len(a)):\n",
      "        # path to feature vector #\n",
      "        path = ''\n",
      "        # numpy array containing features #\n",
      "        npA = [None for k in range(len(ending))]\n",
      "        for frame in a[i]:            \n",
      "            if frame[0] != path:\n",
      "                # load new feature vector only if it was not used already before #\n",
      "                path = frame[0]\n",
      "                for k in range(len(ending)):\n",
      "                    npA[k] = np.load(path.split('.bhvr')[0] + \\\n",
      "                                     '.v{0}.{ending}.npy'.format(i, ending=ending[k]))\n",
      "            f = []\n",
      "            try:\n",
      "                for k in range(len(ending)):\n",
      "                    f += [npA[k][frame[1]].flatten()]\n",
      "            except:\n",
      "                print(\"Problems loading {0}\".format(frame))\n",
      "                \n",
      "            feats += [np.concatenate(tuple(f))]\n",
      "            \n",
      "    return np.asarray(feats)\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeConfusionMatrix(predict, label):\n",
      "    size = np.max(label) + 1\n",
      "    cmat = np.zeros((size, size))\n",
      "    \n",
      "    for i in range(predict.shape[0]):\n",
      "        cmat[label[i], predict[i]] += 1\n",
      "        \n",
      "    return cmat\n",
      "\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "def crossValidateIndependentSamples(data, labels, classifier, Nfolds=2):\n",
      "    idx = np.unique(labels)\n",
      "    cmat = np.zeros((idx.shape[0], idx.shape[0]), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(labels, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    for train, test in kf:\n",
      "        testPos.append(test)\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        trainSet = data[train]\n",
      "        trainLbl = labels[train]\n",
      "        \n",
      "        testSet = data[test]\n",
      "        testLbl.append(labels[test])\n",
      "        \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, testLbl, testPos\n",
      "\n",
      "def crossValidateSampleSets(data, labels, sets, classifier, Nfolds=2):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        data (list of np.arrays)\n",
      "                list of feature matrices, one for each class\n",
      "        labels (list of np.arrays)\n",
      "                list of labels corresponding feature matrices in data\n",
      "        sets (list of [begin (int), end (int)])\n",
      "                list of indeces of sets of groups of samples in feature\n",
      "                matrices\n",
      "                \n",
      "                \n",
      "    \"\"\"\n",
      "    \n",
      "    # construct pseudo feature matrix that in reality contains \n",
      "    # indices to sections in the sets, which will then be used\n",
      "    # to sample from the samples within the choosen sections\n",
      "    # to create unbiased training and test set\n",
      "    \n",
      "    pseudoFeat = [f for s in sets for f in range(len(s))]\n",
      "    pseudoLabel = [i for i in range(len(sets)) for f in range(len(sets[i]))]\n",
      "    \n",
      "    idx = np.max(pseudoLabel)\n",
      "    cmat = np.zeros((idx.shape[0], idx.shape[0]), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(pseudoLabel, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    for train, test in kf:\n",
      "        testPos.append(test)\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        trainSet = data[train]\n",
      "        trainLbl = labels[train]\n",
      "        \n",
      "        testSet = data[test]\n",
      "        testLbl.append(labels[test])\n",
      "        \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, testLbl, testPos\n",
      "\n",
      "def getMissClassified(predict, labels, pathList, cl):\n",
      "    out = []\n",
      "    \n",
      "    for i in range(len(pathList)):\n",
      "        if predict[i] != labels[i] and labels[i] == cl:\n",
      "            out.append(pathList[i])\n",
      "            \n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "aF = []\n",
      "aF += [extractAnnotatedFrames(behaviour=\"struggling\")]\n",
      "aF += [extractAnnotatedFrames(behaviour=\"falling\")]\n",
      "aF += [extractAnnotatedFrames(behaviour=\"dropping\")]\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-20 12:17:10,081 \u001b[0m[T: 140402299045696] \u001b[33m<<module>> \u001b[39m[6] \u001b[1mfinished in 237.902137041 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 237.902137041 sec\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractContinuousAnnotationSections(aF, fileList):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "    \n",
      "    \n",
      "    Returns:\n",
      "        list of list with [begin, end] of sections of continuous appearances\n",
      "        of a label.\n",
      "        `begin` and `end` are as it is required to generate a valid slice\n",
      "        with range(begin, end)\n",
      "\n",
      "    \"\"\"\n",
      "    sect = []#[] for i in range(len(aF))]\n",
      "    for b in range(len(aF)):\n",
      "        sect += [[]]\n",
      "        for v in range(len(aF[b])):\n",
      "            vSec = []\n",
      "            start = 0\n",
      "            end = None\n",
      "            for a in range(1, len(aF[b][v])):\n",
      "                if aF[b][v][a-1][0] ==  aF[b][v][a][0]:\n",
      "                    if aF[b][v][a-1][1] ==  aF[b][v][a][1] - 1:\n",
      "                        continue                        \n",
      "                    else:\n",
      "                        end = a                        \n",
      "                elif aF[b][v][a][1] == 0:\n",
      "                    \n",
      "                    if fileList.index(aF[b][v][a][0].strip('bhvr') + 'pos.npy') \\\n",
      "                    == fileList.index(aF[b][v][a - 1][0].strip('bhvr') + 'pos.npy') + 1:\n",
      "                        pos = np.load(aF[b][v][a - 1][0].strip('bhvr') + 'pos.npy')\n",
      "                        if pos.shape[0] == aF[b][v][a - 1][1] + 1:\n",
      "                            print aF[b][v][a - 1]\n",
      "                            continue\n",
      "                        else:\n",
      "                            end = a\n",
      "                    else:\n",
      "                        end = a\n",
      "                else:\n",
      "                    end = a\n",
      "                    \n",
      "                if end is not None:\n",
      "                    vSec += [[start, end]]\n",
      "                    start = a\n",
      "                    end = None                    \n",
      "                    \n",
      "            vSec += [[start, a + 1]]        \n",
      "            sect[b] += [vSec]\n",
      "            \n",
      "    return sect\n",
      "\n",
      "def flattenAnnotationSections(sect):\n",
      "    out = []\n",
      "    \n",
      "    for a in range(len(sect)):\n",
      "        aSec = []\n",
      "        offSet = 0\n",
      "        for v in range(len(sect[a])):\n",
      "            for i in range(len(sect[a][v])):\n",
      "                aSec += [[sect[a][v][i][0] + offSet, sect[a][v][i][1] + offSet]]\n",
      "            \n",
      "            offSet = aSec[-1][1]\n",
      "            \n",
      "        out += [aSec]\n",
      "        \n",
      "    return out\n",
      "\n",
      "def providePosList(path):\n",
      "    fileList  = []\n",
      "    posList = []\n",
      "    print(\"scaning files...\")\n",
      "    for root,  dirs,  files in os.walk(path):\n",
      "        for f in files:\n",
      "            if f.endswith('pos.npy'):\n",
      "                path = root + '/' + f\n",
      "                fileList.append(path)\n",
      "                \n",
      "    fileList = sorted(fileList)\n",
      "    print(\"scaning files done\")\n",
      "    return fileList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileList = providePosList(dataFolder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "scaning files..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "scaning files done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sect = extractContinuousAnnotationSections(aF, fileList)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130219/00/2013-02-19.00-44-00.bhvr', 1760]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/15/2013-02-20.15-13-00.bhvr', 875]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/21/2013-02-20.21-39-00.bhvr', 875]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flatSect = flattenAnnotationSections(sect)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[len(a) for a in flatSect]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "[77, 52, 1384]"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "ending = ['feat.hog3d', 'feat.hog3d-xy2-t0.5', 'feat.hog-8']\n",
      "# ending = ['feat.hog3d-xy2-t0.5']\n",
      "featS = createFeatureVector(aF[0], ending=ending)\n",
      "featF = createFeatureVector(aF[1], ending=ending)\n",
      "featD = createFeatureVector(aF[2], ending=ending)\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-21 14:28:01,846 \u001b[0m[T: 140402299045696] \u001b[33m<<module>> \u001b[39m[7] \u001b[1mfinished in 137.259781122 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 137.259781122 sec\n"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rngS = np.random.permutation(range(featS.shape[0]))[:181]\n",
      "# rngD = np.random.permutation(range(featD.shape[0]))[:181]\n",
      "\n",
      "feat = np.concatenate(tuple([\\\n",
      "                            featS,\n",
      "                            featF,\n",
      "                            featD]))\n",
      "\n",
      "labels = np.concatenate(tuple([\\\n",
      "                              [0] * featS.shape[0],\n",
      "                              [1] * featF.shape[0],\n",
      "                              [2] * featD.shape[0]]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import grid_search\n",
      "\n",
      "c = RandomForestClassifier(n_jobs=6, criterion='entropy')\n",
      "# c = RandomForestClassifier(n_estimators=50, max_depth=30, n_jobs=6)\n",
      "\n",
      "parameters = {'n_estimators':[1,5,10,20,50,70,100,125,150,175,200,225], 'max_depth':[1, 10,20,30,40,50,60,70,80,90]}\n",
      "\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "\n",
      "clf = grid_search.GridSearchCV(c, parameters)\n",
      "clf.fit(feat, labels)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='entropy', max_depth=None, max_features='auto',\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=10, n_jobs=6, oob_score=False, random_state=None,\n",
        "            verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 5, 10, 20, 50, 70, 100, 125, 150, 175, 200, 225], 'max_depth': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='entropy', max_depth=90, max_features='auto',\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=150, n_jobs=6, oob_score=False, random_state=None,\n",
        "            verbose=0)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "c = RandomForestClassifier(n_estimators=150, max_depth=90, n_jobs=6, criterion='gini')\n",
      "\n",
      "\n",
      "cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[173   8   0]\n",
        " [  1 174   6]\n",
        " [  6  13 162]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# c.fit(feat, labels)\n",
      "\n",
      "rngST = list(set(range(featS.shape[0])).difference(rngS))\n",
      "rngDT = list(set(range(featD.shape[0])).difference(rngD))\n",
      "    \n",
      "featT = np.concatenate(tuple([\\\n",
      "                            featS[rngST],\n",
      "                            featD[rngDT]]))\n",
      "\n",
      "labelsT = np.concatenate(tuple([\\\n",
      "                              [0] * len(rngST),\n",
      "                              [2] * len(rngDT)]))\n",
      "\n",
      "plabels = c.predict(featT)\n",
      "computeConfusionMatrix(plabels, labelsT)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "array([[ 9843.,   282.,    93.],\n",
        "       [    0.,     0.,     0.],\n",
        "       [  129.,   376.,  3962.]])"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances = c.feature_importances_\n",
      "std = np.std([tree.feature_importances_ for tree in c.estimators_],\n",
      "             axis=0)\n",
      "indices = np.argsort(importances)[::-1][:10]\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(10):\n",
      "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
      "\n",
      "# Plot the feature importances of the forest\n",
      "import pylab as pl\n",
      "pl.figure()\n",
      "pl.title(\"Feature importances\")\n",
      "pl.bar(range(10), importances[indices],\n",
      "       color=\"r\", yerr=std[indices], align=\"center\")\n",
      "pl.xticks(range(10), indices)\n",
      "pl.xlim([-1, 10])\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature ranking:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1. feature 325 (0.018451)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2. feature 620 (0.017953)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3. feature 17 (0.015485)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4. feature 1010 (0.014643)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5. feature 781 (0.014251)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6. feature 356 (0.014045)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7. feature 340 (0.010098)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8. feature 1023 (0.009829)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9. feature 33 (0.009811)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10. feature 151 (0.009515)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argsort(importances)[::-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([325, 620,  17, ...,   0, 116, 321])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn import svm\n",
      "\n",
      "\n",
      "# c = svm.SVC()\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.ensemble import AdaBoostClassifier\n",
      "# from sklearn import svm\n",
      "# from sklearn.linear_model import SGDClassifier\n",
      "# from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "# base = c#MultinomialNB()\n",
      "# ada = AdaBoostClassifier(base_estimator=base)\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, ada,  Nfolds=10)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[10359     2    38]\n",
        " [   30    55    96]\n",
        " [   86     0  4562]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = set(range(featS.shape[0])).difference(rngS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "10218"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featS.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "10399"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%qtconsole"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = time.localtime()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.tmm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}