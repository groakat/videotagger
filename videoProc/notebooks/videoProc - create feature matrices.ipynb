{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "import os\n",
      "import pyTools.videoProc.annotation as annotation\n",
      "import pyTools.system.videoExplorer as videoExplorer\n",
      "import pyTools.misc.config as cfg\n",
      "import pyTools.misc.basic as bsc\n",
      "import time\n",
      "import operator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataFolder = '/run/media/peter/Elements/peter/data/tmp-20130506'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "behaviour = \"struggling\"\n",
      "annotator = \"peter\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractAnnotatedFrames(vials=None, annotator=\"peter\", behaviour=\"struggling\", \n",
      "                           dataFolder='/run/media/peter/Elements/peter/data/tmp-20130506'):\n",
      "    \n",
      "    filt = annotation.AnnotationFilter(vials, [annotator], [behaviour])\n",
      "#     frames = []\n",
      "    \n",
      "    # list of filtered frames (one list for each vial)\n",
      "    a = [[] for i in range(4)]\n",
      "    \n",
      "    for root, dirs, files in os.walk(dataFolder):\n",
      "        for file in files:\n",
      "            if file.endswith(\".bhvr\"):\n",
      "                # load annotation and filter it #\n",
      "                path = os.path.join(root,file)\n",
      "                anno = annotation.Annotation()\n",
      "        \n",
      "                anno.loadFromFile(path)\n",
      "                filteredAnno = anno.filterFrameList(filt)\n",
      "                \n",
      "                if behaviour in anno.behaviours and annotator in anno.annotators:\n",
      "                    # extract frame numbers corresponding to filter #\n",
      "                    frameList = [[i, x] for i, x in enumerate(filteredAnno.frameList)  \\\n",
      "                                             if x is not None]\n",
      "                    \n",
      "                    # sort frames into the different vials to know what\n",
      "                    # feature files we will have to load later #\n",
      "                    if frameList:\n",
      "                        for f in frameList:\n",
      "#                             frames += [[path, f[0]]]\n",
      "                            for v in range(len(a)):\n",
      "                                if f[1][v] is not None:\n",
      "                                    a[v] += [[path.split('.bhvr')[0] + '.pos.npy', f[0]]]\n",
      "                    \n",
      "    return a\n",
      "\n",
      "def extractNegativeAnnotatedFrames(vials=None, annotator=\"peter\", behaviours=[\"struggling\"], \n",
      "                           dataFolder='/run/media/peter/Elements/peter/data/tmp-20130506',\n",
      "                           samplesNo=10000):\n",
      "    \"\"\"\n",
      "    Extracts frames that do not contain any of the given behaviours.\n",
      "    \n",
      "    The algorithm samples frames randomly from the given `dataFolder` and verifies that they\n",
      "    are not labelled with the given annotations\n",
      "    \n",
      "    TODO: needs refinement in vial selection\n",
      "    \"\"\"\n",
      "#     frames = []\n",
      "    noVials = 3\n",
      "    \n",
      "    # list of filtered frames (one list for each vial)\n",
      "    a = [[] for i in range(3)]\n",
      "    \n",
      "    fileList = []\n",
      "    for root, dirs, files in os.walk(dataFolder):\n",
      "        for file in files:\n",
      "            if file.endswith(\".bhvr\"):\n",
      "                fileList += [os.path.join(root,file)]\n",
      "                \n",
      "    fileList.sort() \n",
      "    \n",
      "    for i in range(samplesNo):\n",
      "        # random selection of file (not the first or last one because some features\n",
      "        # might not be extracted for them)\n",
      "        fileIdx = np.int32(np.floor(np.random.random() * (len(fileList) - 2))) + 1\n",
      "        # random selection of vial\n",
      "        vIdx = np.int32(np.floor(np.random.random() * noVials))\n",
      "        \n",
      "        # load annotation and filter it #\n",
      "        path = os.path.join(fileList[fileIdx])\n",
      "        anno = annotation.Annotation()\n",
      "        anno.loadFromFile(path)\n",
      "        \n",
      "        # random selection of frame\n",
      "        negativeFrames = range(len(anno.frameList))\n",
      "        for behaviour in behaviours:\n",
      "            annoFrames = anno.getFramesWithBehaviour(behaviour, [vIdx])\n",
      "            negativeFrames = set(negativeFrames).difference(annoFrames)\n",
      "            \n",
      "        if not negativeFrames:\n",
      "            # if we get here, that means that all frames\n",
      "            # in the given vial are annotated by the behaviour\n",
      "            i -= 1\n",
      "            continue\n",
      "        else:\n",
      "            selFrameIdx = np.random.permutation(list(negativeFrames))[0]\n",
      "            a[vIdx] += [[path.split('.bhvr')[0] + '.pos.npy', selFrameIdx]]\n",
      "        \n",
      "        \n",
      "                    \n",
      "    return a\n",
      "                    \n",
      "\n",
      "       \n",
      "# cfg.log.info(\"finished in {0} sec\".format(time.time() - t))   \n",
      "\n",
      "def createFeatureVector(a, ending=['feat.hog3d']):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        a (list [[path, int]]):\n",
      "                    list of paths with corresponding\n",
      "                    frame numbers\n",
      "                    see :func:`extractAnnotatedFrames`\n",
      "    \"\"\"\n",
      "    # feature matrix #\n",
      "    feats = []\n",
      "    for i in range(len(a)):\n",
      "        # path to feature vector #\n",
      "        path = ''\n",
      "        # numpy array containing features #\n",
      "        npA = [None for k in range(len(ending))]\n",
      "        for frame in a[i]:            \n",
      "            if frame[0] != path:\n",
      "                # load new feature vector only if it was not used already before #\n",
      "                path = frame[0]\n",
      "                for k in range(len(ending)):\n",
      "                    npA[k] = np.load(path.split('.pos.npy')[0] + \\\n",
      "                                     '.v{0}.{ending}.npy'.format(i, ending=ending[k]))\n",
      "            f = []\n",
      "            try:\n",
      "                for k in range(len(ending)):\n",
      "                    f += [npA[k][frame[1]].flatten()]\n",
      "            except:\n",
      "                print(\"Problems loading {0}\".format(frame))\n",
      "                \n",
      "            feats += [np.concatenate(tuple(f))]\n",
      "            \n",
      "    return np.asarray(feats)\n",
      "\n",
      "def createFeatureVectorFromAnnotationSections(aS, ending=['feat.hog3d']):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        a (list [[path, int]]):\n",
      "                    list of paths with corresponding\n",
      "                    frame numbers\n",
      "                    see :func:`extractAnnotatedFrames`\n",
      "    \"\"\"\n",
      "    # feature matrix #\n",
      "    feats = []\n",
      "    aCnt = 0\n",
      "    for a in aS:\n",
      "        aCnt += 1\n",
      "        # path to feature vector #\n",
      "        path = ''\n",
      "        vial = -1\n",
      "        # numpy array containing features #\n",
      "        npA = [None for k in range(len(ending))]\n",
      "        featSs = []\n",
      "        \n",
      "        sCnt = 0\n",
      "        for section in a:            \n",
      "            sCnt += 1\n",
      "            featFs = []\n",
      "            for frame in section:\n",
      "                if frame[0] != path or frame[2] != vial:\n",
      "                    # load new feature vector only if it was not used already before #\n",
      "                    path = copy.copy(frame[0])\n",
      "                    vial = frame[2]\n",
      "                    for k in range(len(ending)):\n",
      "                        npA[k] = np.load(path.split('.pos.npy')[0] + \\\n",
      "                                         '.v{0}.{ending}.npy'.format(vial, ending=ending[k]))\n",
      "                f = []\n",
      "                try:\n",
      "                    for k in range(len(ending)):\n",
      "                        f += [npA[k][frame[1]].flatten()]\n",
      "                except:\n",
      "                    print(\"Problems loading {0}\".format(frame))\n",
      "                \n",
      "                featFs += [np.concatenate(tuple(f))]\n",
      "            \n",
      "            feat = np.asarray(featFs)\n",
      "            if feat.shape == (0,):\n",
      "                print frame\n",
      "                \n",
      "            featSs += [feat]\n",
      "        \n",
      "        feats += [featSs]        \n",
      "                \n",
      "            \n",
      "    return feats\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeConfusionMatrix(predict, label):\n",
      "    size = np.max(label) + 1\n",
      "    cmat = np.zeros((size, size))\n",
      "    \n",
      "    for i in range(predict.shape[0]):\n",
      "        cmat[label[i], predict[i]] += 1\n",
      "        \n",
      "    return cmat\n",
      "\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "def crossValidateIndependentSamples(data, labels, classifier, Nfolds=2):\n",
      "    idx = np.unique(labels)\n",
      "    cmat = np.zeros((idx.shape[0], idx.shape[0]), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(labels, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    for train, test in kf:\n",
      "        testPos.append(test)\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        trainSet = data[train]\n",
      "        trainLbl = labels[train]\n",
      "        \n",
      "        testSet = data[test]\n",
      "        testLbl.append(labels[test])\n",
      "        \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, testLbl, testPos\n",
      "\n",
      "def crossValidateSampleSets(data, labels, sets, classifier, Nfolds=2):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        data (list of np.arrays)\n",
      "                list of feature matrices, one for each class\n",
      "        labels (list of np.arrays)\n",
      "                list of labels corresponding feature matrices in data\n",
      "        sets (list of [begin (int), end (int)])\n",
      "                list of indeces of sets of groups of samples in feature\n",
      "                matrices\n",
      "                \n",
      "                \n",
      "    \"\"\"\n",
      "    \n",
      "    # construct pseudo feature matrix that in reality contains \n",
      "    # indices to sections in the sets, which will then be used\n",
      "    # to sample from the samples within the choosen sections\n",
      "    # to create unbiased training and test set\n",
      "    \n",
      "    pseudoFeat = np.asarray([f for s in sets for f in range(len(s))])\n",
      "    pseudoLabel = np.asarray([i for i in range(len(sets)) for f in range(len(sets[i]))])\n",
      "    \n",
      "    idx = np.max(pseudoLabel) + 1\n",
      "    cmat = np.zeros((idx, idx), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(pseudoLabel, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    trainSets = []\n",
      "    testSets = []\n",
      "    \n",
      "    for train, test in kf:\n",
      "        testPos.append(test)\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        \n",
      "        # create balanced training set\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            cFeat += [[i for t in train \\\n",
      "                           if pseudoLabel[t] == c \\\n",
      "                               for i in range(*sets[pseudoLabel[t]][pseudoFeat[t]])]]\n",
      "            \n",
      "        maxSamples = min([len(a) for a in cFeat])\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        selection = []\n",
      "        for c in range(len(cFeat)):\n",
      "            idces = np.random.permutation(np.asarray(cFeat[c]))[:maxSamples]\n",
      "            feats += [data[c][idces]]\n",
      "            lbls += [[c] * maxSamples]\n",
      "            selection += [idces]\n",
      "            \n",
      "                \n",
      "        trainSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        trainSets += [selection]\n",
      "        trainLbl = np.concatenate(tuple(lbls)) #labels[train]\n",
      "        \n",
      "        \n",
      "        # create test set from all samples in sets choosen for testing\n",
      "        # (class imbalance does not matter)\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            cFeat += [[i for t in test \\\n",
      "                           if pseudoLabel[t] == c \\\n",
      "                               for i in range(*sets[pseudoLabel[t]][pseudoFeat[t]])]]\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        for c in range(len(cFeat)):\n",
      "            feats += [data[c][cFeat[c]]]\n",
      "            lbls += [[c] * len(cFeat[c])]\n",
      "            \n",
      "                \n",
      "        testSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        testSets += [cFeat]\n",
      "        testLbl.append(np.concatenate(tuple(lbls))) #labels[train]\n",
      "        \n",
      "        \n",
      "        # train classifier and test \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, trainSets, testSets\n",
      "\n",
      "\n",
      "def getPseudoIndeces(sets):    \n",
      "    # construct pseudo feature matrix that in reality contains \n",
      "    # indices to sections in the sets, which will then be used\n",
      "    # to sample from the samples within the choosen sections\n",
      "    # to create unbiased training and test set\n",
      "    pseudoFeat = np.asarray([f for s in sets for f in range(len(s))])\n",
      "    pseudoLabel = np.asarray([i for i in range(len(sets)) for f in range(len(sets[i]))])\n",
      "    \n",
      "    return pseudoFeat, pseudoLabel\n",
      "\n",
      "def crossValidateSectionSets(sets, classifier, Nfolds=2):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        data (list of np.arrays)\n",
      "                list of feature matrices, one for each class\n",
      "        labels (list of np.arrays)\n",
      "                list of labels corresponding feature matrices in data\n",
      "        sets (list of [begin (int), end (int)])\n",
      "                list of indeces of sets of groups of samples in feature\n",
      "                matrices\n",
      "                \n",
      "                \n",
      "    \"\"\"\n",
      "    \n",
      "    # construct pseudo feature matrix that in reality contains \n",
      "    # indices to sections in the sets, which will then be used\n",
      "    # to sample from the samples within the choosen sections\n",
      "    # to create unbiased training and test set\n",
      "    \n",
      "#     pseudoFeat = np.asarray([f for s in sets for f in range(len(s))])\n",
      "#     pseudoLabel = np.asarray([i for i in range(len(sets)) for f in range(len(sets[i]))])\n",
      "    \n",
      "    pseudoFeat, pseudoLabel = getPseudoIndeces(sets)\n",
      "    \n",
      "    idx = np.max(pseudoLabel) + 1\n",
      "    cmat = np.zeros((idx, idx), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(pseudoLabel, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    trainSets = []\n",
      "    testSets = []\n",
      "    selectionSet = []\n",
      "    \n",
      "    for train, test in kf:\n",
      "        trainSets += [train]\n",
      "        testSets += [test]\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        \n",
      "        # create balanced training set\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            abc = [sets[pseudoLabel[t]][pseudoFeat[t]] \\\n",
      "                                               for t in train \\\n",
      "                                                   if pseudoLabel[t] == c ]\n",
      "#             for a in abc:\n",
      "#                 print a.shape\n",
      "            cFeat += [np.concatenate(abc)]\n",
      "        \n",
      "        \n",
      "        maxSamples = min([a.shape[0] for a in cFeat])\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        selection = []\n",
      "        for c in range(len(cFeat)):\n",
      "            idces = np.random.permutation(np.arange(cFeat[c].shape[0]))[:maxSamples]\n",
      "            feats += [cFeat[c][idces]]\n",
      "            lbls += [[c] * maxSamples]\n",
      "            selection += [idces]\n",
      "            \n",
      "                \n",
      "        trainSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        selectionSet += [selection]\n",
      "        trainLbl = np.concatenate(tuple(lbls)) #labels[train]\n",
      "        \n",
      "        \n",
      "        # create test set from all samples in sets choosen for testing\n",
      "        # (class imbalance does not matter)\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            cFeat += [np.concatenate(tuple([sets[pseudoLabel[t]][pseudoFeat[t]] \\\n",
      "                                               for t in test \\\n",
      "                                                   if pseudoLabel[t] == c ]))]\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        for c in range(len(cFeat)):\n",
      "            feats += [cFeat[c]]\n",
      "            lbls += [[c] * cFeat[c].shape[0]]\n",
      "            \n",
      "                \n",
      "        testSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        testLbl.append(np.concatenate(tuple(lbls))) #labels[train]\n",
      "        \n",
      "        \n",
      "        # train classifier and test \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, trainSets, testSets, selectionSet\n",
      "\n",
      "def getMissClassified(predict, labels, pathList, cl):\n",
      "    out = []\n",
      "    \n",
      "    for i in range(len(pathList)):\n",
      "        if predict[i] != labels[i] and labels[i] == cl:\n",
      "            out.append(pathList[i])\n",
      "            \n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "aF = []\n",
      "aF += [extractAnnotatedFrames(behaviour=\"falling\")]\n",
      "aF += [extractAnnotatedFrames(behaviour=\"dropping\")]\n",
      "aF += [extractAnnotatedFrames(behaviour=\"struggling\")]\n",
      "aF += [extractNegativeAnnotatedFrames(behaviours=[\"falling\", \"dropping\", \"struggling\"])]\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-25 15:50:54,037 \u001b[0m[T: 139969002428224] \u001b[33m<<module>> \u001b[39m[7] \u001b[1mfinished in 418.516542912 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 418.516542912 sec\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import deque\n",
      "import copy\n",
      "\n",
      "def extractContinuousAnnotationSections(aF, fileList):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "    \n",
      "    \n",
      "    Returns:\n",
      "        list of list with [begin, end] of sections of continuous appearances\n",
      "        of a label.\n",
      "        `begin` and `end` are as it is required to generate a valid slice\n",
      "        with range(begin, end)\n",
      "\n",
      "    \"\"\"\n",
      "    sect = []#[] for i in range(len(aF))]\n",
      "    for b in range(len(aF)):\n",
      "        sect += [[]]\n",
      "        for v in range(len(aF[b])):\n",
      "            vSec = []\n",
      "            start = 0\n",
      "            end = None\n",
      "            for a in range(1, len(aF[b][v])):\n",
      "                if aF[b][v][a-1][0] ==  aF[b][v][a][0]:\n",
      "                    if aF[b][v][a-1][1] ==  aF[b][v][a][1] - 1:\n",
      "                        continue                        \n",
      "                    else:\n",
      "                        end = a                        \n",
      "                elif aF[b][v][a][1] == 0:\n",
      "                    \n",
      "                    if fileList.index(aF[b][v][a][0]) \\\n",
      "                    == fileList.index(aF[b][v][a - 1][0]) + 1:\n",
      "                        pos = np.load(aF[b][v][a - 1][0])\n",
      "                        if pos.shape[0] == aF[b][v][a - 1][1] + 1:\n",
      "                            print aF[b][v][a - 1]\n",
      "                            continue\n",
      "                        else:\n",
      "                            end = a\n",
      "                    else:\n",
      "                        end = a\n",
      "                else:\n",
      "                    end = a\n",
      "                    \n",
      "                if end is not None:\n",
      "                    vSec += [[start, end]]\n",
      "                    start = a\n",
      "                    end = None                    \n",
      "                    \n",
      "            vSec += [[start, a + 1]]        \n",
      "            sect[b] += [vSec]\n",
      "            \n",
      "    return sect\n",
      "\n",
      "\n",
      "def extendAnnotationSections(aF, sections, fileList, additionalFrames=0):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "    \n",
      "    \n",
      "    Returns:\n",
      "        list of list with [begin, end] of sections of continuous appearances\n",
      "        of a label.\n",
      "        `begin` and `end` are as it is required to generate a valid slice\n",
      "        with range(begin, end)\n",
      "\n",
      "    \"\"\"\n",
      "    aS = []\n",
      "    \n",
      "    for a in range(len(sections)):\n",
      "        classSects = []\n",
      "        for v in range(len(sections[a])):\n",
      "            for s in range(len(sections[a][v])):\n",
      "                frameList = deque()\n",
      "                start = copy.copy(aF[a][v][sections[a][v][s][0]])\n",
      "                end = copy.copy(aF[a][v][sections[a][v][s][1] - 1])\n",
      "                \n",
      "                remainingFrames = additionalFrames\n",
      "                \n",
      "                while remainingFrames > 0:                 \n",
      "                    remainingFrames -= 1\n",
      "                    start[1] -= 1                    \n",
      "                    if start[1] < 0:\n",
      "                        filePos = fileList.index(start[0])\n",
      "                        if filePos < 1:\n",
      "                            cfg.log.warning(\\\n",
      "                            'tried to include frames previous to the first frame {0} {1} {2}'.format(a,v,s))\n",
      "                            break\n",
      "                        start[0] = fileList[filePos - 1]\n",
      "                        start[1] = np.load(start[0]).shape[0] - 1\n",
      "                        \n",
      "                    frameList.appendleft(copy.copy(start) + [v])   \n",
      "\n",
      "                \n",
      "                for i in range(*sections[a][v][s]):\n",
      "                    frameList.append(copy.copy(aF[a][v][i]) + [v])\n",
      "                \n",
      "                curLength = np.load(end[0]).shape[0]\n",
      "                remainingFrames = additionalFrames\n",
      "                \n",
      "                \n",
      "                while remainingFrames > 0:               \n",
      "                    remainingFrames -= 1\n",
      "                    end[1] += 1\n",
      "                    \n",
      "                    if end[1] >= curLength:\n",
      "                        filePos = fileList.index(end[0])\n",
      "                        if filePos >= len(fileList) - 1:\n",
      "                            cfg.log.warning(\\\n",
      "                            'tried to include frames after to the last frame {0} {1} {2}'.format(a,v,s))\n",
      "                            break\n",
      "                        end[0] = fileList[filePos + 1]\n",
      "                        curLength = np.load(end[0]).shape[0]\n",
      "                        end[1] = 0\n",
      "                        \n",
      "                    frameList.append(copy.copy(end) + [v])     \n",
      "                        \n",
      "                if len(frameList) == 0:\n",
      "                    print a,v,sections[a][v]\n",
      "                    \n",
      "                classSects += [frameList]\n",
      "                \n",
      "        aS += [classSects]\n",
      "                            \n",
      "    return aS\n",
      "\n",
      "\n",
      "def flattenAnnotationSections(sect):\n",
      "    out = []\n",
      "    \n",
      "    for a in range(len(sect)):\n",
      "        aSec = []\n",
      "        offSet = 0\n",
      "        for v in range(len(sect[a])):\n",
      "            for i in range(len(sect[a][v])):\n",
      "                aSec += [[sect[a][v][i][0] + offSet, sect[a][v][i][1] + offSet]]\n",
      "            \n",
      "            offSet = aSec[-1][1]\n",
      "            \n",
      "        out += [aSec]\n",
      "        \n",
      "    return out\n",
      "\n",
      "def providePosList(path):\n",
      "    fileList  = []\n",
      "    posList = []\n",
      "    print(\"scaning files...\")\n",
      "    for root,  dirs,  files in os.walk(path):\n",
      "        for f in files:\n",
      "            if f.endswith('pos.npy'):\n",
      "                path = root + '/' + f\n",
      "                fileList.append(path)\n",
      "                \n",
      "    fileList = sorted(fileList)\n",
      "    print(\"scaning files done\")\n",
      "    return fileList\n",
      "\n",
      "def flattenAnnotatedFrames(aF):\n",
      "    flattenedAF = []\n",
      "    for a in aF:     \n",
      "        aList = []\n",
      "        for v in range(len(a)):\n",
      "            aList += [i + [v] for i in a[v]]\n",
      "        flattenedAF += [aList]\n",
      "        \n",
      "    return flattenedAF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileList = providePosList(dataFolder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "scaning files..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "scaning files done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sect = extractContinuousAnnotationSections(aF, fileList)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/20/2013-02-20.20-38-00.pos.npy', 875]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/21/2013-02-20.21-11-00.pos.npy', 875]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aS = []\n",
      "additionalFrames = 0\n",
      "s = sect[0:3]\n",
      "aS += extendAnnotationSections(aF[0:3], s, fileList, additionalFrames)\n",
      "aS += extendAnnotationSections([aF[3]], [sect[3]], fileList, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sortKey(x):\n",
      "    op = operator.itemgetter(0,2)\n",
      "    return op(x[0])\n",
      "\n",
      "# if aS[3] is sorted (first path then vialno), the feature import (next step will hopefully be faster)\n",
      "aS[3] = sorted(aS[3], key=sortKey)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%qtconsole"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "# ending = ['feat.hog3d', 'feat.hog3d-xy2-t0.5', 'feat.hog3d-xy1-t0.25', 'feat.hog3d-xy2-t0.25', 'feat.hog-8', 'feat.position']\n",
      "ending = ['feat.hog3d', 'feat.position']\n",
      "# ending = ['feat.hog3d-xy2-t0.5']\n",
      "feat = createFeatureVectorFromAnnotationSections(aS, ending=ending)\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-25 16:01:12,732 \u001b[0m[T: 139969002428224] \u001b[33m<<module>> \u001b[39m[6] \u001b[1mfinished in 502.905912876 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 502.905912876 sec\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveMILData(data, additionalFrames=100, negBags=5000):\n",
      "    \"\"\"\n",
      "    data[0] is the positive class\n",
      "    data[1] is the negative class    \n",
      "    \n",
      "    output format will be\n",
      "    \n",
      "    instance name (just a running integer), bag name (ID), instance label (0/1), features\n",
      "    \"\"\"\n",
      "    aF = additionalFrames\n",
      "    \n",
      "    id = 0\n",
      "    bagList = []\n",
      "    # process posivite bags\n",
      "    for bP in range(len(data[0])):\n",
      "        negIID1 = np.arange(id, id+aF).reshape(aF,1)\n",
      "        id += aF\n",
      "        bagID1 = np.zeros((aF,1)) + bP\n",
      "        negFeat1 = data[0][bP][:aF]        \n",
      "        negPt1 = np.hstack((negIID1, bagID1, negFeat1))\n",
      "    \n",
      "        noPos = data[0][bP].shape[0] - 2 * aF\n",
      "        posID = np.arange(id, id + noPos).reshape(noPos,1)\n",
      "        id += noPos\n",
      "        bagID2 = np.zeros((noPos,1)) + bP\n",
      "        posFeat1 = data[0][bP][aF:-aF]\n",
      "        posPt = np.hstack((posID, bagID2, posFeat1))\n",
      "        \n",
      "        negIID2 = np.arange(id, id+aF).reshape(aF,1)\n",
      "        id += aF\n",
      "        bagID3 = np.zeros((aF,1)) + bP\n",
      "        negFeat2 = data[0][bP][-aF:]\n",
      "        negPt2 = np.hstack((negIID2,bagID3, negFeat2))\n",
      "        \n",
      "        bagList += [np.vstack((negPt1, posPt, negPt2))]\n",
      "        \n",
      "        \n",
      "    bagID = bP\n",
      "    for bag in partition(data[1], negBags):\n",
      "        noInst = len(bag)\n",
      "        \n",
      "        ids = np.arange(id, id+noInst).reshape(noInst,1)\n",
      "        id += noInst\n",
      "        \n",
      "        bagIDs = np.zeros((noInst,1)) + bagID\n",
      "        bagID += 1\n",
      "        \n",
      "        feats = np.vstack(bag)\n",
      "        \n",
      "        bagList += [np.hstack((ids, bagIDs, feats))]\n",
      "        \n",
      "        \n",
      "    return np.vstack(bagList)\n",
      "        \n",
      "        \n",
      "def partition ( lst, n ):\n",
      "    for i in range(n):\n",
      "        yield lst[i::]\n",
      "    \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "milData = saveMILData([feat[0], feat[3]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import grid_search\n",
      "\n",
      "c = RandomForestClassifier(n_jobs=6, n_estimators=160, max_depth=60)\n",
      "\n",
      "cmat, predict, trainSet, testSet, selectionSet = crossValidateSectionSets(feat, c,  Nfolds=10)\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 126   30    2   23]\n",
        " [ 300 4184   84   80]\n",
        " [ 197   67 9841  294]\n",
        " [  19  235  433 9310]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flatSect = flattenAnnotationSections(sect)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 326
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat[0][0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "(4, 314)"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[len(a) for a in flatSect]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 327,
       "text": [
        "[52, 1384, 78]"
       ]
      }
     ],
     "prompt_number": 327
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "# ending = ['feat.hog3d', 'feat.hog3d-xy2-t0.5', 'feat.hog3d-xy1-t0.25', 'feat.hog3d-xy2-t0.25', 'feat.hog-8', 'feat.pos']\n",
      "ending = ['feat.hog3d', 'feat.pos']\n",
      "# ending = ['feat.hog3d-xy2-t0.5']\n",
      "featS = createFeatureVector(aF[0], ending=ending)\n",
      "featF = createFeatureVector(aF[1], ending=ending)\n",
      "featD = createFeatureVector(aF[2], ending=ending)\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-23 20:02:24,603 \u001b[0m[T: 140402299045696] \u001b[33m<<module>> \u001b[39m[8] \u001b[1mfinished in 12.1003558636 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 12.1003558636 sec\n"
       ]
      }
     ],
     "prompt_number": 361
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat =[featS, featF, featD]\n",
      "labels = [[0] * featS.shape[0], [1] * featF.shape[0], [2] * featD.shape[0]]\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import grid_search\n",
      "\n",
      "c = RandomForestClassifier(n_jobs=6, n_estimators=100, max_depth=50)\n",
      "\n",
      "cmat, predict, trainSets, testSets = crossValidateSampleSets(feat, labels, flatSect, c,  Nfolds=10)\n",
      "\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  126    48     7]\n",
        " [  318  4214   116]\n",
        " [  279    87 10033]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aF[0][0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 285,
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130219/00/2013-02-19.00-06-00.bhvr',\n",
        " 1600,\n",
        " 0]"
       ]
      }
     ],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flattenedAF = flattenAnnotatedFrames(aF)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 330
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveConfusionMatrix(predict, testSet, aS, baseDir='/tmp/cmat'):\n",
      "    folder = lambda l,p: os.path.join(baseDir, '{0}-{1}'.format(l,p))    \n",
      "    vE = videoExplorer.videoExplorer()\n",
      "    \n",
      "    pseudoFeat, pseudoLabel = getPseudoIndeces(aS)\n",
      "    \n",
      "    size = max(pseudoLabel) + 1\n",
      "    cmat = np.zeros((size, size))\n",
      "    \n",
      "    for i in range(size):\n",
      "        for k in range(size):\n",
      "            if not os.path.exists(folder(i,k)):\n",
      "                os.makedirs(folder(i,k))        \n",
      "             \n",
      "    \n",
      "    for test in range(len(testSet)):\n",
      "        k = 0\n",
      "        for t in testSet[test]:\n",
      "            l = pseudoLabel[t]\n",
      "            section = aS[l][pseudoFeat[t]]\n",
      "            for f in section:\n",
      "                basePath = f[0].split('.pos.npy')[0]\n",
      "                frameNo = f[1]\n",
      "                vialNo = f[2]\n",
      "                p = predict[test][k]\n",
      "             \n",
      "                fn = '{base}-v{vial}-f{frame}.png'.format(\\\n",
      "                        base=os.path.split(basePath)[-1],\n",
      "                        vial=vialNo,\n",
      "                        frame=frameNo)\n",
      "                savePath = os.path.join(folder(l,p), fn)\n",
      "                \n",
      "                videoPath = '{base}.v{vial}.avi'.format(\\\n",
      "                        base=basePath,\n",
      "                        vial=vialNo)\n",
      "                \n",
      "                saveFrameTo(vE, videoPath, frameNo, savePath, 'RGB')\n",
      "                \n",
      "                \n",
      "                cmat[l, p] += 1\n",
      "                \n",
      "                k += 1\n",
      "        \n",
      "    return cmat\n",
      "\n",
      "from ffvideo import VideoStream\n",
      "def saveFrameTo(self, videoPath, frameNo, filePath, frameMode='L'):\n",
      "    import scipy\n",
      "    frames = []\n",
      "    self.vs = VideoStream(videoPath, frame_mode=frameMode)      \n",
      "    for i in range(-1,2):\n",
      "        try:\n",
      "            frames += [np.rot90(self.vs.get_frame_no(frameNo + i).ndarray())]\n",
      "        except:\n",
      "            pass\n",
      "        \n",
      "    frame = np.concatenate(tuple(frames), axis=1)    \n",
      "    scipy.misc.imsave(filePath, frame)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saveConfusionMatrix(predict, testSet, aS)   \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flattenedAF[0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 333,
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130219/00/2013-02-19.00-06-00.bhvr',\n",
        " 1597,\n",
        " 0]"
       ]
      }
     ],
     "prompt_number": 333
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(testSets)):\n",
      "    saveConfusionMatrix(predict[i], testSets[i], flattenedAF)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 360
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.arange(9).reshape((3,3))\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 1 2]\n",
        " [3 4 5]\n",
        " [6 7 8]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 344
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.rot90(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 346,
       "text": [
        "array([[2, 5, 8],\n",
        "       [1, 4, 7],\n",
        "       [0, 3, 6]])"
       ]
      }
     ],
     "prompt_number": 346
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rngS = np.random.permutation(range(featS.shape[0]))[:181]\n",
      "# rngD = np.random.permutation(range(featD.shape[0]))[:181]\n",
      "\n",
      "feat = np.concatenate(tuple([\\\n",
      "                            featS,\n",
      "                            featF,\n",
      "                            featD]))\n",
      "\n",
      "labels = np.concatenate(tuple([\\\n",
      "                              [0] * featS.shape[0],\n",
      "                              [1] * featF.shape[0],\n",
      "                              [2] * featD.shape[0]]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import grid_search\n",
      "\n",
      "c = RandomForestClassifier(n_jobs=6, criterion='entropy')\n",
      "# c = RandomForestClassifier(n_estimators=50, max_depth=30, n_jobs=6)\n",
      "\n",
      "parameters = {'n_estimators':[1,5,10,20,50,70,100,125,150,175,200,225], 'max_depth':[1, 10,20,30,40,50,60,70,80,90]}\n",
      "\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "\n",
      "clf = grid_search.GridSearchCV(c, parameters)\n",
      "clf.fit(feat, labels)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='entropy', max_depth=None, max_features='auto',\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=10, n_jobs=6, oob_score=False, random_state=None,\n",
        "            verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 5, 10, 20, 50, 70, 100, 125, 150, 175, 200, 225], 'max_depth': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='entropy', max_depth=90, max_features='auto',\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=150, n_jobs=6, oob_score=False, random_state=None,\n",
        "            verbose=0)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "c = RandomForestClassifier(n_estimators=150, max_depth=90, n_jobs=6, criterion='gini')\n",
      "\n",
      "\n",
      "cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[173   8   0]\n",
        " [  1 174   6]\n",
        " [  6  13 162]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# c.fit(feat, labels)\n",
      "\n",
      "rngST = list(set(range(featS.shape[0])).difference(rngS))\n",
      "rngDT = list(set(range(featD.shape[0])).difference(rngD))\n",
      "    \n",
      "featT = np.concatenate(tuple([\\\n",
      "                            featS[rngST],\n",
      "                            featD[rngDT]]))\n",
      "\n",
      "labelsT = np.concatenate(tuple([\\\n",
      "                              [0] * len(rngST),\n",
      "                              [2] * len(rngDT)]))\n",
      "\n",
      "plabels = c.predict(featT)\n",
      "computeConfusionMatrix(plabels, labelsT)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "array([[ 9843.,   282.,    93.],\n",
        "       [    0.,     0.,     0.],\n",
        "       [  129.,   376.,  3962.]])"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances = c.feature_importances_\n",
      "std = np.std([tree.feature_importances_ for tree in c.estimators_],\n",
      "             axis=0)\n",
      "indices = np.argsort(importances)[::-1][:10]\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(10):\n",
      "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
      "\n",
      "# Plot the feature importances of the forest\n",
      "import pylab as pl\n",
      "pl.figure()\n",
      "pl.title(\"Feature importances\")\n",
      "pl.bar(range(10), importances[indices],\n",
      "       color=\"r\", yerr=std[indices], align=\"center\")\n",
      "pl.xticks(range(10), indices)\n",
      "pl.xlim([-1, 10])\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature ranking:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1. feature 325 (0.018451)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2. feature 620 (0.017953)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3. feature 17 (0.015485)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4. feature 1010 (0.014643)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5. feature 781 (0.014251)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6. feature 356 (0.014045)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7. feature 340 (0.010098)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8. feature 1023 (0.009829)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9. feature 33 (0.009811)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10. feature 151 (0.009515)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argsort(importances)[::-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([325, 620,  17, ...,   0, 116, 321])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn import svm\n",
      "\n",
      "\n",
      "# c = svm.SVC()\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.ensemble import AdaBoostClassifier\n",
      "# from sklearn import svm\n",
      "# from sklearn.linear_model import SGDClassifier\n",
      "# from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "# base = c#MultinomialNB()\n",
      "# ada = AdaBoostClassifier(base_estimator=base)\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, ada,  Nfolds=10)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[10359     2    38]\n",
        " [   30    55    96]\n",
        " [   86     0  4562]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = set(range(featS.shape[0])).difference(rngS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "10218"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featS.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "10399"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%qtconsole"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = time.localtime()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.tmm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}