{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "import os\n",
      "import pyTools.videoProc.annotation as annotation\n",
      "import pyTools.system.videoExplorer as videoExplorer\n",
      "import pyTools.misc.config as cfg\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataFolder = '/run/media/peter/Elements/peter/data/tmp-20130506'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "behaviour = \"struggling\"\n",
      "annotator = \"peter\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractAnnotatedFrames(vials=None, annotator=\"peter\", behaviour=\"struggling\", \n",
      "                           dataFolder='/run/media/peter/Elements/peter/data/tmp-20130506'):\n",
      "    \n",
      "    filt = annotation.AnnotationFilter(vials, [annotator], [behaviour])\n",
      "#     frames = []\n",
      "    \n",
      "    # list of filtered frames (one list for each vial)\n",
      "    a = [[] for i in range(4)]\n",
      "    \n",
      "    for root, dirs, files in os.walk(dataFolder):\n",
      "        for file in files:\n",
      "            if file.endswith(\".bhvr\"):\n",
      "                # load annotation and filter it #\n",
      "                path = os.path.join(root,file)\n",
      "                anno = annotation.Annotation()\n",
      "        \n",
      "                anno.loadFromFile(path)\n",
      "                filteredAnno = anno.filterFrameList(filt)\n",
      "                \n",
      "                if behaviour in anno.behaviours and annotator in anno.annotators:\n",
      "                    # extract frame numbers corresponding to filter #\n",
      "                    frameList = [[i, x] for i, x in enumerate(filteredAnno.frameList)  \\\n",
      "                                             if x is not None]\n",
      "                    \n",
      "                    # sort frames into the different vials to know what\n",
      "                    # feature files we will have to load later #\n",
      "                    if frameList:\n",
      "                        for f in frameList:\n",
      "#                             frames += [[path, f[0]]]\n",
      "                            for v in range(len(a)):\n",
      "                                if f[1][v] is not None:\n",
      "                                    a[v] += [[path.split('.bhvr')[0] + '.pos.npy', f[0]]]\n",
      "                    \n",
      "    return a\n",
      "\n",
      "def extractNegativeAnnotatedFrames(vials=None, annotator=\"peter\", behaviours=[\"struggling\"], \n",
      "                           dataFolder='/run/media/peter/Elements/peter/data/tmp-20130506',\n",
      "                           samplesNo=10000):\n",
      "    \"\"\"\n",
      "    Extracts frames that do not contain any of the given behaviours.\n",
      "    \n",
      "    The algorithm samples frames randomly from the given `dataFolder` and verifies that they\n",
      "    are not labelled with the given annotations\n",
      "    \n",
      "    TODO: needs refinement in vial selection\n",
      "    \"\"\"\n",
      "#     frames = []\n",
      "    \n",
      "    # list of filtered frames (one list for each vial)\n",
      "    a = [[] for i in range(3)]\n",
      "    \n",
      "    fileList = []\n",
      "    for root, dirs, files in os.walk(dataFolder):\n",
      "        for file in files:\n",
      "            if file.endswith(\".bhvr\"):\n",
      "                fileList += [os.path.join(root,file)]\n",
      "                \n",
      "    fileList.sort() \n",
      "    \n",
      "    for i in range(samplesNo):\n",
      "        # random selection of file (not the first or last one because some features\n",
      "        # might not be extracted for them)\n",
      "        fileIdx = np.int32(np.floor(np.random.random() * (len(fileList) - 2))) + 1\n",
      "        # random selection of vial\n",
      "        vIdx = np.int32(np.floor(np.random.random() * len(a)))\n",
      "        \n",
      "        # load annotation and filter it #\n",
      "        path = os.path.join(fileList[fileIdx])\n",
      "        anno = annotation.Annotation()\n",
      "        anno.loadFromFile(path)\n",
      "        \n",
      "        # random selection of frame\n",
      "        negativeFrames = range(len(anno.frameList))\n",
      "        for behaviour in behaviours:\n",
      "            annoFrames = anno.getFramesWithBehaviour(behaviour, [vIdx])\n",
      "            negativeFrames = set(negativeFrames).difference(annoFrames)\n",
      "            \n",
      "        if not negativeFrames:\n",
      "            # if we get here, that means that all frames\n",
      "            # in the given vial are annotated by the behaviour\n",
      "            i -= 1\n",
      "            continue\n",
      "        else:\n",
      "            selFrameIdx = np.random.permutation(list(negativeFrames))[0]\n",
      "            a[vIdx] += [[path.split('.bhvr')[0] + '.pos.npy', selFrameIdx]]\n",
      "        \n",
      "        \n",
      "                    \n",
      "    return a\n",
      "                    \n",
      "\n",
      "       \n",
      "# cfg.log.info(\"finished in {0} sec\".format(time.time() - t))   \n",
      "\n",
      "def createFeatureVector(a, ending=['feat.hog3d']):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        a (list [[path, int]]):\n",
      "                    list of paths with corresponding\n",
      "                    frame numbers\n",
      "                    see :func:`extractAnnotatedFrames`\n",
      "    \"\"\"\n",
      "    # feature matrix #\n",
      "    feats = []\n",
      "    for i in range(len(a)):\n",
      "        # path to feature vector #\n",
      "        path = ''\n",
      "        # numpy array containing features #\n",
      "        npA = [None for k in range(len(ending))]\n",
      "        for frame in a[i]:            \n",
      "            if frame[0] != path:\n",
      "                # load new feature vector only if it was not used already before #\n",
      "                path = frame[0]\n",
      "                for k in range(len(ending)):\n",
      "                    npA[k] = np.load(path.split('.pos.npy')[0] + \\\n",
      "                                     '.v{0}.{ending}.npy'.format(i, ending=ending[k]))\n",
      "            f = []\n",
      "            try:\n",
      "                for k in range(len(ending)):\n",
      "                    f += [npA[k][frame[1]].flatten()]\n",
      "            except:\n",
      "                print(\"Problems loading {0}\".format(frame))\n",
      "                \n",
      "            feats += [np.concatenate(tuple(f))]\n",
      "            \n",
      "    return np.asarray(feats)\n",
      "\n",
      "def createFeatureVectorFromAnnotationSections(aS, ending=['feat.hog3d']):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        a (list [[path, int]]):\n",
      "                    list of paths with corresponding\n",
      "                    frame numbers\n",
      "                    see :func:`extractAnnotatedFrames`\n",
      "    \"\"\"\n",
      "    # feature matrix #\n",
      "    feats = []\n",
      "    aCnt = 0\n",
      "    for a in aS:\n",
      "        aCnt += 1\n",
      "        # path to feature vector #\n",
      "        path = ''\n",
      "        vial = -1\n",
      "        # numpy array containing features #\n",
      "        npA = [None for k in range(len(ending))]\n",
      "        featSs = []\n",
      "        \n",
      "        sCnt = 0\n",
      "        for section in a:            \n",
      "            sCnt += 1\n",
      "            featFs = []\n",
      "            for frame in section:\n",
      "                if frame[0] != path or frame[2] != vial:\n",
      "                    # load new feature vector only if it was not used already before #\n",
      "                    path = copy.copy(frame[0])\n",
      "                    vial = frame[2]\n",
      "                    for k in range(len(ending)):\n",
      "                        npA[k] = np.load(path.split('.pos.npy')[0] + \\\n",
      "                                         '.v{0}.{ending}.npy'.format(vial, ending=ending[k]))\n",
      "                f = []\n",
      "                try:\n",
      "                    for k in range(len(ending)):\n",
      "                        f += [npA[k][frame[1]].flatten()]\n",
      "                except:\n",
      "                    print(\"Problems loading {0}\".format(frame))\n",
      "                \n",
      "                featFs += [np.concatenate(tuple(f))]\n",
      "            \n",
      "            feat = np.asarray(featFs)\n",
      "            if feat.shape == (0,):\n",
      "                print frame\n",
      "                \n",
      "            featSs += [feat]\n",
      "        \n",
      "        feats += [featSs]        \n",
      "                \n",
      "            \n",
      "    return feats\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeConfusionMatrix(predict, label):\n",
      "    size = np.max(label) + 1\n",
      "    cmat = np.zeros((size, size))\n",
      "    \n",
      "    for i in range(predict.shape[0]):\n",
      "        cmat[label[i], predict[i]] += 1\n",
      "        \n",
      "    return cmat\n",
      "\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "def crossValidateIndependentSamples(data, labels, classifier, Nfolds=2):\n",
      "    idx = np.unique(labels)\n",
      "    cmat = np.zeros((idx.shape[0], idx.shape[0]), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(labels, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    for train, test in kf:\n",
      "        testPos.append(test)\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        trainSet = data[train]\n",
      "        trainLbl = labels[train]\n",
      "        \n",
      "        testSet = data[test]\n",
      "        testLbl.append(labels[test])\n",
      "        \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, testLbl, testPos\n",
      "\n",
      "def crossValidateSampleSets(data, labels, sets, classifier, Nfolds=2):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        data (list of np.arrays)\n",
      "                list of feature matrices, one for each class\n",
      "        labels (list of np.arrays)\n",
      "                list of labels corresponding feature matrices in data\n",
      "        sets (list of [begin (int), end (int)])\n",
      "                list of indeces of sets of groups of samples in feature\n",
      "                matrices\n",
      "                \n",
      "                \n",
      "    \"\"\"\n",
      "    \n",
      "    # construct pseudo feature matrix that in reality contains \n",
      "    # indices to sections in the sets, which will then be used\n",
      "    # to sample from the samples within the choosen sections\n",
      "    # to create unbiased training and test set\n",
      "    \n",
      "    pseudoFeat = np.asarray([f for s in sets for f in range(len(s))])\n",
      "    pseudoLabel = np.asarray([i for i in range(len(sets)) for f in range(len(sets[i]))])\n",
      "    \n",
      "    idx = np.max(pseudoLabel) + 1\n",
      "    cmat = np.zeros((idx, idx), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(pseudoLabel, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    trainSets = []\n",
      "    testSets = []\n",
      "    \n",
      "    for train, test in kf:\n",
      "        testPos.append(test)\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        \n",
      "        # create balanced training set\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            cFeat += [[i for t in train \\\n",
      "                           if pseudoLabel[t] == c \\\n",
      "                               for i in range(*sets[pseudoLabel[t]][pseudoFeat[t]])]]\n",
      "            \n",
      "        maxSamples = min([len(a) for a in cFeat])\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        selection = []\n",
      "        for c in range(len(cFeat)):\n",
      "            idces = np.random.permutation(np.asarray(cFeat[c]))[:maxSamples]\n",
      "            feats += [data[c][idces]]\n",
      "            lbls += [[c] * maxSamples]\n",
      "            selection += [idces]\n",
      "            \n",
      "                \n",
      "        trainSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        trainSets += [selection]\n",
      "        trainLbl = np.concatenate(tuple(lbls)) #labels[train]\n",
      "        \n",
      "        \n",
      "        # create test set from all samples in sets choosen for testing\n",
      "        # (class imbalance does not matter)\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            cFeat += [[i for t in test \\\n",
      "                           if pseudoLabel[t] == c \\\n",
      "                               for i in range(*sets[pseudoLabel[t]][pseudoFeat[t]])]]\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        for c in range(len(cFeat)):\n",
      "            feats += [data[c][cFeat[c]]]\n",
      "            lbls += [[c] * len(cFeat[c])]\n",
      "            \n",
      "                \n",
      "        testSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        testSets += [cFeat]\n",
      "        testLbl.append(np.concatenate(tuple(lbls))) #labels[train]\n",
      "        \n",
      "        \n",
      "        # train classifier and test \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, trainSets, testSets\n",
      "\n",
      "def crossValidateSectionSets(sets, classifier, Nfolds=2):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        data (list of np.arrays)\n",
      "                list of feature matrices, one for each class\n",
      "        labels (list of np.arrays)\n",
      "                list of labels corresponding feature matrices in data\n",
      "        sets (list of [begin (int), end (int)])\n",
      "                list of indeces of sets of groups of samples in feature\n",
      "                matrices\n",
      "                \n",
      "                \n",
      "    \"\"\"\n",
      "    \n",
      "    # construct pseudo feature matrix that in reality contains \n",
      "    # indices to sections in the sets, which will then be used\n",
      "    # to sample from the samples within the choosen sections\n",
      "    # to create unbiased training and test set\n",
      "    \n",
      "    pseudoFeat = np.asarray([f for s in sets for f in range(len(s))])\n",
      "    pseudoLabel = np.asarray([i for i in range(len(sets)) for f in range(len(sets[i]))])\n",
      "    \n",
      "    idx = np.max(pseudoLabel) + 1\n",
      "    cmat = np.zeros((idx, idx), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(pseudoLabel, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    trainSets = []\n",
      "    testSets = []\n",
      "    selectionSet = []\n",
      "    \n",
      "    for train, test in kf:\n",
      "        trainSets += [train]\n",
      "        testSets += [test]\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        \n",
      "        # create balanced training set\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            abc = [sets[pseudoLabel[t]][pseudoFeat[t]] \\\n",
      "                                               for t in train \\\n",
      "                                                   if pseudoLabel[t] == c ]\n",
      "#             for a in abc:\n",
      "#                 print a.shape\n",
      "            cFeat += [np.concatenate(abc)]\n",
      "        \n",
      "        \n",
      "        maxSamples = min([a.shape[0] for a in cFeat])\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        selection = []\n",
      "        for c in range(len(cFeat)):\n",
      "            idces = np.random.permutation(np.arange(cFeat[c].shape[0]))[:maxSamples]\n",
      "            feats += [cFeat[c][idces]]\n",
      "            lbls += [[c] * maxSamples]\n",
      "            selection += [idces]\n",
      "            \n",
      "                \n",
      "        trainSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        selectionSet += [selection]\n",
      "        trainLbl = np.concatenate(tuple(lbls)) #labels[train]\n",
      "        \n",
      "        \n",
      "        # create test set from all samples in sets choosen for testing\n",
      "        # (class imbalance does not matter)\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            cFeat += [np.concatenate(tuple([sets[pseudoLabel[t]][pseudoFeat[t]] \\\n",
      "                                               for t in test \\\n",
      "                                                   if pseudoLabel[t] == c ]))]\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        for c in range(len(cFeat)):\n",
      "            feats += [cFeat[c]]\n",
      "            lbls += [[c] * cFeat[c].shape[0]]\n",
      "            \n",
      "                \n",
      "        testSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        testLbl.append(np.concatenate(tuple(lbls))) #labels[train]\n",
      "        \n",
      "        \n",
      "        # train classifier and test \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, trainSet, testSet, selectionSet\n",
      "\n",
      "def getMissClassified(predict, labels, pathList, cl):\n",
      "    out = []\n",
      "    \n",
      "    for i in range(len(pathList)):\n",
      "        if predict[i] != labels[i] and labels[i] == cl:\n",
      "            out.append(pathList[i])\n",
      "            \n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "aF = []\n",
      "aF += [extractAnnotatedFrames(behaviour=\"falling\")]\n",
      "aF += [extractAnnotatedFrames(behaviour=\"dropping\")]\n",
      "aF += [extractAnnotatedFrames(behaviour=\"struggling\")]\n",
      "aF += [extractNegativeAnnotatedFrames(behaviours=[\"falling\", \"dropping\", \"struggling\"])]\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-25 12:40:10,072 \u001b[0m[T: 139904492799808] \u001b[33m<<module>> \u001b[39m[6] \u001b[1mfinished in 236.630578995 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 236.630578995 sec\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aF[3] = extractNegativeAnnotatedFrames(behaviours=[\"falling\", \"dropping\", \"struggling\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import deque\n",
      "import copy\n",
      "\n",
      "def extractContinuousAnnotationSections(aF, fileList):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "    \n",
      "    \n",
      "    Returns:\n",
      "        list of list with [begin, end] of sections of continuous appearances\n",
      "        of a label.\n",
      "        `begin` and `end` are as it is required to generate a valid slice\n",
      "        with range(begin, end)\n",
      "\n",
      "    \"\"\"\n",
      "    sect = []#[] for i in range(len(aF))]\n",
      "    for b in range(len(aF)):\n",
      "        sect += [[]]\n",
      "        for v in range(len(aF[b])):\n",
      "            vSec = []\n",
      "            start = 0\n",
      "            end = None\n",
      "            for a in range(1, len(aF[b][v])):\n",
      "                if aF[b][v][a-1][0] ==  aF[b][v][a][0]:\n",
      "                    if aF[b][v][a-1][1] ==  aF[b][v][a][1] - 1:\n",
      "                        continue                        \n",
      "                    else:\n",
      "                        end = a                        \n",
      "                elif aF[b][v][a][1] == 0:\n",
      "                    \n",
      "                    if fileList.index(aF[b][v][a][0]) \\\n",
      "                    == fileList.index(aF[b][v][a - 1][0]) + 1:\n",
      "                        pos = np.load(aF[b][v][a - 1][0])\n",
      "                        if pos.shape[0] == aF[b][v][a - 1][1] + 1:\n",
      "                            print aF[b][v][a - 1]\n",
      "                            continue\n",
      "                        else:\n",
      "                            end = a\n",
      "                    else:\n",
      "                        end = a\n",
      "                else:\n",
      "                    end = a\n",
      "                    \n",
      "                if end is not None:\n",
      "                    vSec += [[start, end]]\n",
      "                    start = a\n",
      "                    end = None                    \n",
      "                    \n",
      "            vSec += [[start, a + 1]]        \n",
      "            sect[b] += [vSec]\n",
      "            \n",
      "    return sect\n",
      "\n",
      "\n",
      "def extendAnnotationSections(aF, sections, fileList, additionalFrames=0):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "    \n",
      "    \n",
      "    Returns:\n",
      "        list of list with [begin, end] of sections of continuous appearances\n",
      "        of a label.\n",
      "        `begin` and `end` are as it is required to generate a valid slice\n",
      "        with range(begin, end)\n",
      "\n",
      "    \"\"\"\n",
      "    aS = []\n",
      "    \n",
      "    for a in range(len(sections)):\n",
      "        classSects = []\n",
      "        for v in range(len(sections[a])):\n",
      "            for s in range(len(sections[a][v])):\n",
      "                frameList = deque()\n",
      "                start = copy.copy(aF[a][v][sections[a][v][s][0]])\n",
      "                end = copy.copy(aF[a][v][sections[a][v][s][1] - 1])\n",
      "                \n",
      "                remainingFrames = additionalFrames\n",
      "                \n",
      "                while remainingFrames > 0:                 \n",
      "                    remainingFrames -= 1\n",
      "                    start[1] -= 1                    \n",
      "                    if start[1] < 0:\n",
      "                        filePos = fileList.index(start[0])\n",
      "                        if filePos < 1:\n",
      "                            cfg.log.warning(\\\n",
      "                            'tried to include frames previous to the first frame {0} {1} {2}'.format(a,v,s))\n",
      "                            break\n",
      "                        start[0] = fileList[filePos - 1]\n",
      "                        start[1] = np.load(start[0]).shape[0] - 1\n",
      "                        \n",
      "                    frameList.appendleft(copy.copy(start) + [v])   \n",
      "\n",
      "                \n",
      "                for i in range(*sections[a][v][s]):\n",
      "                    frameList.append(copy.copy(aF[a][v][i]) + [v])\n",
      "                \n",
      "                curLength = np.load(end[0]).shape[0]\n",
      "                remainingFrames = additionalFrames\n",
      "                \n",
      "                \n",
      "                while remainingFrames > 0:               \n",
      "                    remainingFrames -= 1\n",
      "                    end[1] += 1\n",
      "                    \n",
      "                    if end[1] >= curLength:\n",
      "                        filePos = fileList.index(end[0])\n",
      "                        if filePos >= len(fileList) - 1:\n",
      "                            cfg.log.warning(\\\n",
      "                            'tried to include frames after to the last frame {0} {1} {2}'.format(a,v,s))\n",
      "                            break\n",
      "                        end[0] = fileList[filePos + 1]\n",
      "                        curLength = np.load(end[0]).shape[0]\n",
      "                        end[1] = 0\n",
      "                        \n",
      "                    frameList.append(copy.copy(end) + [v])     \n",
      "                        \n",
      "                if len(frameList) == 0:\n",
      "                    print a,v,sections[a][v]\n",
      "                    \n",
      "                classSects += [frameList]\n",
      "                \n",
      "        aS += [classSects]\n",
      "                            \n",
      "    return aS\n",
      "\n",
      "\n",
      "def flattenAnnotationSections(sect):\n",
      "    out = []\n",
      "    \n",
      "    for a in range(len(sect)):\n",
      "        aSec = []\n",
      "        offSet = 0\n",
      "        for v in range(len(sect[a])):\n",
      "            for i in range(len(sect[a][v])):\n",
      "                aSec += [[sect[a][v][i][0] + offSet, sect[a][v][i][1] + offSet]]\n",
      "            \n",
      "            offSet = aSec[-1][1]\n",
      "            \n",
      "        out += [aSec]\n",
      "        \n",
      "    return out\n",
      "\n",
      "def providePosList(path):\n",
      "    fileList  = []\n",
      "    posList = []\n",
      "    print(\"scaning files...\")\n",
      "    for root,  dirs,  files in os.walk(path):\n",
      "        for f in files:\n",
      "            if f.endswith('pos.npy'):\n",
      "                path = root + '/' + f\n",
      "                fileList.append(path)\n",
      "                \n",
      "    fileList = sorted(fileList)\n",
      "    print(\"scaning files done\")\n",
      "    return fileList\n",
      "\n",
      "def flattenAnnotatedFrames(aF):\n",
      "    flattenedAF = []\n",
      "    for a in aF:     \n",
      "        aList = []\n",
      "        for v in range(len(a)):\n",
      "            aList += [i + [v] for i in a[v]]\n",
      "        flattenedAF += [aList]\n",
      "        \n",
      "    return flattenedAF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileList = providePosList(dataFolder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "scaning files..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "scaning files done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sect = extractContinuousAnnotationSections(aF, fileList)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/20/2013-02-20.20-38-00.pos.npy', 875]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/21/2013-02-20.21-11-00.pos.npy', 875]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aF[0][2][-5:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "[['/run/media/peter/Elements/peter/data/tmp-20130506/20130219/20/2013-02-19.20-44-00.pos.npy',\n",
        "  874],\n",
        " ['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/20/2013-02-20.20-33-00.pos.npy',\n",
        "  55],\n",
        " ['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/20/2013-02-20.20-33-00.pos.npy',\n",
        "  56],\n",
        " ['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/20/2013-02-20.20-33-00.pos.npy',\n",
        "  57],\n",
        " ['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/20/2013-02-20.20-38-00.pos.npy',\n",
        "  13]]"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aS = extendAnnotationSections(aF, sect, fileList, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "# ending = ['feat.hog3d', 'feat.hog3d-xy2-t0.5', 'feat.hog3d-xy1-t0.25', 'feat.hog3d-xy2-t0.25', 'feat.hog-8', 'feat.position']\n",
      "ending = ['feat.hog3d', 'feat.position']\n",
      "# ending = ['feat.hog3d-xy2-t0.5']\n",
      "feat = createFeatureVectorFromAnnotationSections(aS, ending=ending)\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-25 13:26:35,585 \u001b[0m[T: 139904492799808] \u001b[33m<<module>> \u001b[39m[6] \u001b[1mfinished in 550.480556011 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 550.480556011 sec\n"
       ]
      }
     ],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import grid_search\n",
      "\n",
      "c = RandomForestClassifier(n_jobs=6, n_estimators=160, max_depth=60)\n",
      "\n",
      "cmat, predict, trainSet, testSet, selectionSet = crossValidateSectionSets(feat, c,  Nfolds=10)\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:227: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:227: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:227: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:227: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:227: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:227: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:227: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:227: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:227: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:227: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 131   25    1   24]\n",
        " [ 347 4138   86   77]\n",
        " [ 240   76 9801  282]\n",
        " [  23  201  385 9391]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flatSect = flattenAnnotationSections(sect)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 326
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat[0][0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "(4, 314)"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[len(a) for a in flatSect]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 327,
       "text": [
        "[52, 1384, 78]"
       ]
      }
     ],
     "prompt_number": 327
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "# ending = ['feat.hog3d', 'feat.hog3d-xy2-t0.5', 'feat.hog3d-xy1-t0.25', 'feat.hog3d-xy2-t0.25', 'feat.hog-8', 'feat.pos']\n",
      "ending = ['feat.hog3d', 'feat.pos']\n",
      "# ending = ['feat.hog3d-xy2-t0.5']\n",
      "featS = createFeatureVector(aF[0], ending=ending)\n",
      "featF = createFeatureVector(aF[1], ending=ending)\n",
      "featD = createFeatureVector(aF[2], ending=ending)\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-23 20:02:24,603 \u001b[0m[T: 140402299045696] \u001b[33m<<module>> \u001b[39m[8] \u001b[1mfinished in 12.1003558636 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 12.1003558636 sec\n"
       ]
      }
     ],
     "prompt_number": 361
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat =[featS, featF, featD]\n",
      "labels = [[0] * featS.shape[0], [1] * featF.shape[0], [2] * featD.shape[0]]\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import grid_search\n",
      "\n",
      "c = RandomForestClassifier(n_jobs=6, n_estimators=100, max_depth=50)\n",
      "\n",
      "cmat, predict, trainSets, testSets = crossValidateSampleSets(feat, labels, flatSect, c,  Nfolds=10)\n",
      "\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  126    48     7]\n",
        " [  318  4214   116]\n",
        " [  279    87 10033]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fold = 2\n",
      "print [sorted(a) for a in trainSets[fold]]\n",
      "print \"\\n\"\n",
      "print [len(a) for a in trainSets[fold]]\n",
      "print \"\\n\"\n",
      "print [sorted(a) for a in testSets[fold]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[14, 15, 44, 130, 198, 218, 290, 292, 571, 583, 667, 690, 742, 819, 829, 1015, 1028, 1205, 1236, 1294, 1389, 1427, 1466, 1523, 1631, 1633, 1642, 1689, 1698, 1749, 1779, 1797, 1837, 1844, 1869, 1874, 1909, 2004, 2121, 2226, 2326, 2355, 2408, 2508, 2554, 2564, 2623, 2847, 2852, 2899, 2926, 2942, 3055, 3113, 3140, 3158, 3220, 3271, 3306, 3320, 3425, 3460, 3484, 3524, 3571, 3665, 3741, 3756, 3797, 3811, 3871, 4117, 4119, 4166, 4183, 4251, 4253, 4299, 4320, 4349, 4376, 4386, 4399, 4520, 4565, 4571, 4722, 4731, 4790, 4805, 5003, 5039, 5069, 5133, 5136, 5153, 5644, 5665, 5667, 5752, 5808, 5832, 6002, 6045, 6161, 6181, 6187, 6192, 6195, 6239, 6392, 6407, 6433, 6470, 6541, 6555, 6556, 6558, 6593, 6648, 6691, 6709, 7073, 7141, 7162, 7165, 7236, 7279, 7302, 7321, 7337, 7358, 7371, 7591, 7626, 7910, 7951, 7992, 8009, 8073, 8213, 8356, 8411, 8435, 8452, 8453, 8510, 8525, 8535, 8641, 8774, 8950, 8990, 9015, 9070, 9171, 9189, 9221, 9313, 9355, 9380, 9448, 9572, 9633, 10347, 10353, 10368], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180], [4, 48, 100, 103, 139, 144, 158, 174, 188, 193, 195, 219, 221, 233, 238, 256, 278, 279, 329, 336, 365, 376, 391, 460, 480, 564, 589, 698, 725, 818, 823, 826, 828, 859, 939, 945, 1002, 1023, 1045, 1048, 1063, 1068, 1123, 1148, 1154, 1244, 1270, 1287, 1288, 1308, 1376, 1406, 1440, 1496, 1548, 1565, 1573, 1682, 1718, 1746, 1791, 1876, 1891, 1912, 1927, 1952, 1999, 2008, 2011, 2026, 2037, 2049, 2064, 2085, 2111, 2141, 2142, 2149, 2161, 2171, 2270, 2292, 2335, 2338, 2384, 2415, 2428, 2533, 2560, 2573, 2593, 2601, 2602, 2635, 2649, 2655, 2673, 2678, 2717, 2738, 2741, 2769, 2775, 2788, 2824, 2858, 2890, 2916, 2928, 2956, 2964, 2995, 3005, 3009, 3025, 3038, 3043, 3052, 3089, 3116, 3146, 3235, 3246, 3252, 3320, 3410, 3430, 3495, 3662, 3715, 3737, 3745, 3746, 3747, 3791, 3850, 3853, 3865, 3876, 4002, 4009, 4037, 4039, 4076, 4086, 4163, 4176, 4182, 4187, 4195, 4229, 4285, 4300, 4314, 4333, 4362, 4371, 4422, 4447, 4448, 4520, 4567, 4589, 4619, 4635, 4645, 4646]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[167, 167, 167]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 3922, 3923, 3924, 3925, 3926, 3927, 3928, 3929, 3930, 3931, 3932, 3933, 3934, 3935, 3936, 3937, 3938, 3939, 3940, 3941, 3942, 3943, 3944, 3945, 3946, 3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956, 3957, 3958, 3959, 3960, 3961, 3962, 3963, 3964, 3965, 3966, 3967, 3968, 3969, 3970, 3971, 3972, 3973, 3974, 3975, 3976, 3977, 3978, 3979, 3980, 3981, 3982, 3983, 3984, 3985, 3986, 3987, 3988, 3989, 3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999, 4000, 4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4009, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4037, 4038, 4039, 4040, 4041, 4042, 4043, 4044, 4045, 4046, 4047, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4055, 4056, 4057, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4068, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4078, 5168, 5169, 5170, 5171, 5172, 5173, 5174, 5175, 5176, 5177, 5178, 5179, 5180, 5181, 5182, 5183, 5184, 5185, 5186, 5187, 5188, 5189, 5190, 5191, 5192, 5193, 5194, 5195, 5196, 5197, 5198, 5199, 5200, 5201, 5202, 5203, 5204, 5205, 5206, 5207, 5208, 5209, 5210, 5211, 5212, 5213, 5214, 5215, 5216, 5217, 5218, 5219, 5220, 5221, 5222, 5223, 5224, 5225, 5226, 5227, 5228, 5229, 5230, 5231, 5232, 5233, 5234, 5235, 5236, 5237, 5238, 5239, 5240, 5241, 5242, 5243, 5244, 5245, 5246, 5247, 5248, 5249, 5250, 5251, 5252, 5253, 5254, 5255, 5256, 5257, 5258, 5259, 5260, 5261, 5262, 5263, 5264, 5265, 5266, 5267, 5268, 5269, 5270, 5271, 5272, 5273, 5274, 5275, 5276, 5277, 5278, 5279, 5280, 5281, 5282, 5283, 5284, 5285, 5286, 5287, 5288, 5289, 5290, 5291, 5292, 5293, 5294, 5295, 5296, 5297, 5298, 5299, 5300, 5301, 5302, 5303, 5304, 5305, 5306, 5307, 5308, 5309, 5310, 5311, 5312, 5313, 5314, 5315, 5316, 5317, 5318, 5319, 5320, 5321, 5322, 5323, 5324, 5325, 5326, 5327, 5328, 5329, 5330, 5331, 5332, 5333, 5334, 5335, 5336, 5337, 5338, 5339, 5340, 5341, 5342, 5343, 5344, 5345, 5346, 5347, 5348, 5349, 5350, 5351, 5352, 5353, 5354, 5355, 5356, 5357, 5358, 5359, 5360, 5361, 5362, 5363, 5364, 5365, 5366, 5367, 5368, 5369, 5370, 5371, 5372, 5373, 5374, 5375, 5376, 5377, 5378, 5379, 5380, 5381, 5382, 5383, 5384, 5385, 5386, 5387, 5388, 5389, 5390, 5391, 5392, 5393, 5394, 5395, 5396, 5397, 5398, 5399, 5400, 5401, 5402, 5403, 5404, 5405, 5406, 5407, 5408, 5409, 5410, 5411, 5412, 5413, 5414, 5415, 5416, 5417, 5418, 5419, 5420, 5421, 5422, 5423, 5424, 5425, 5426, 5427, 5428, 5429, 5430, 5431, 5432, 5433, 5434, 5435, 5436, 5437, 5438, 5439, 5440, 5441, 5442, 5443, 5444, 5445, 5446, 5447, 5448, 5449, 5450, 5451, 5452, 5453, 5454, 5455, 5456, 5457, 5458, 5459, 5460, 5461, 5462, 5463, 5464, 5465, 5466, 5467, 5468, 5469, 5470, 5471, 5472, 5473, 5474, 5475, 5476, 5477, 5478, 5479, 5480, 5481, 5482, 5483, 5484, 5485, 5486, 5487, 5488, 5489, 5490, 5491, 5492, 5493, 5494, 5495, 5496, 5497, 5498, 5499, 5500, 5501, 5502, 5503, 5504, 5505, 5506, 5507, 5508, 5509, 5510, 5511, 5512, 5513, 5514, 5515, 5516, 5517, 5518, 5519, 5520, 5521, 5522, 5523, 5524, 5525, 5526, 5527, 5528, 5529, 5530, 5531, 5532, 5533, 5534, 5535, 5536, 5537, 5538, 5539, 5540, 5541, 5542, 5543, 5544, 5545, 5546, 5547, 5548, 5549, 5550, 5551, 5552, 5553, 5554, 5555, 5556, 5557, 5558, 5559, 5560, 5561, 5562, 5563, 5564, 5565, 5566, 5567, 5568, 5569, 5570, 5571, 5572, 5573, 5574, 5575, 5576, 5577, 5578, 5579, 5580, 5581, 5582, 5583, 5584, 5585, 5586, 5587, 5588, 5589, 5590, 5591, 5592, 5593, 5594, 5595, 6718, 6719, 6720, 6721, 6722, 6723, 6724, 6725, 6726, 6727, 6728, 6729, 6730, 6731, 6732, 6733, 6734, 6735, 6736, 6737, 6738, 6739, 6740, 6741, 6742, 6743, 6744, 6745, 6746, 6747, 6748, 6749, 6750, 6751, 6752, 6753, 6754, 6755, 6756, 6757, 6758, 6759, 6760, 6761, 6762, 6763, 6764, 6765, 6766, 6767, 6768, 6769, 6770, 6771, 6772, 6773, 6774, 6775, 6776, 6777, 6778, 6779, 6780, 6781, 6782, 6783, 6784, 6785, 6786, 6787, 6788, 6789, 6790, 6791, 6792, 6793, 6794, 6795, 6796, 6797, 6798, 6799, 6800, 6801, 6802, 6803, 6804, 6805, 6806, 6807, 6808, 6809, 6810, 6811, 6812, 6813, 6814, 6815, 7488, 7489, 7490, 7491, 7492, 7493, 7494, 7495, 7496, 7497, 7498, 7499, 7500, 7501, 7502, 7503, 7504, 7505, 7506, 7507, 7508, 7509, 7510, 7511, 7512, 7513, 7514, 7515, 7516, 7517, 7518, 7519, 7520, 7521, 7522, 7523, 7524, 7525, 7526, 7527, 7528, 7529, 7530, 7531, 7532, 7533, 7534, 7535, 7536, 7537, 7538, 7539, 7540, 7541, 7542, 7543, 7544, 7545, 7546, 7547, 7548, 7549, 7550, 7551, 7552, 7553, 7554, 7555, 7556, 7557, 7558, 7559, 7560, 7561, 7562, 7563, 7564, 7565, 7566, 7567, 7568, 7569, 7570, 7571, 7572, 7573, 7574, 7575, 7576, 7577, 7578, 7579, 7580, 7581, 7582, 7583, 7584, 7585, 7586, 7587, 7588, 7589, 7590, 8662, 8663, 8664, 8665, 8666, 8667, 8668, 8669, 8670, 8671, 8672, 8673, 8674, 8675, 8676, 8677, 8678, 8679, 8680, 8681, 8682, 8683, 8684, 8685, 8686, 8687, 8688, 8689, 8690, 8691, 8692, 8693, 8694, 8695, 8696, 8697, 8698, 8699, 8700, 8701, 8702, 8703, 8704, 8705, 8706, 8707, 8708, 8709, 8710, 8711, 8712, 8713, 8714, 8715, 8716, 8717, 8718, 8719, 8720, 8721, 8722, 8723, 8724, 8725, 8726, 8727, 8728, 8729, 8730, 8731, 8732, 8733, 8734, 8735, 8736, 8737, 8738, 8739, 8740, 8741, 8742, 8743, 8744, 8745, 8746, 8747, 8748, 8749, 9741, 9742, 9743, 9744, 9745, 9746, 9747, 9748, 9749, 9750, 9751, 9752, 9753, 9754, 9755, 9756, 9757, 9758, 9759, 9760, 9761, 9762, 9763, 9764, 9765, 9766, 9767, 9768, 9769, 9770, 9771, 9772, 9773, 9774, 9775, 9776, 9777, 9778, 9779, 9780, 9781, 9782, 9783, 9784, 9785, 9786, 9787, 9788, 9789, 9790, 9791, 9792, 9793, 9794, 9795, 9796, 9797, 9798, 9799, 9800, 9801, 9802, 9803, 9804, 9805, 9806, 9807, 9808, 9809, 9810, 9811, 9812, 9813, 9814, 9815, 9816, 9817, 9818, 9819, 9820, 9821, 9822, 9823, 9824, 9825, 9826, 9827, 9828, 9829, 9830, 9831, 9832, 9833, 9834, 9835, 9836, 9837, 9838, 9839, 9840, 9841, 9842, 9843, 9844, 9845, 9846, 9847, 9848, 9849, 9850, 9851, 9852, 9853, 9854, 9855, 9856, 9857, 9858, 9859, 9860, 9861, 9862, 9863, 9864, 9865, 9866, 9867, 9868, 9869, 9870, 9871, 9872, 9873, 9874, 9875, 9876, 9877, 9878, 9879, 9880, 9881, 9882, 9883, 9884, 9885, 9886, 9887, 9888, 9889, 9890, 9891, 9892, 9893, 9894, 9895, 9896, 9897, 9898, 9899, 9900, 9901, 9902, 9903, 9904, 9905, 9906, 9907, 9908, 9909, 9910, 9911, 9912, 9913, 9914, 9915, 9916, 9917, 9918, 9919, 9920, 9921, 9922, 9923, 9924, 9925, 9926, 9927, 9928, 9929, 9930, 9931, 9932, 9933, 9934, 9935, 9936, 9937, 9938, 9939, 9940, 9941, 9942, 9943, 9944, 9945, 9946, 9947, 9948, 9949, 9950, 9951, 9952, 9953, 9954, 9955, 9956, 9957, 9958, 9959, 9960, 9961, 9962, 9963, 9964, 9965, 9966, 9967, 9968, 9969, 9970, 9971, 9972, 9973, 9974, 9975, 9976, 9977, 9978, 9979, 9980, 9981, 9982, 9983, 9984, 9985, 9986, 9987, 9988, 9989, 9990, 9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000, 10001, 10002, 10003, 10004, 10005, 10006, 10007, 10008, 10009, 10010, 10011, 10012, 10013, 10014, 10015, 10016, 10017, 10018, 10019, 10020, 10021, 10022, 10023, 10024, 10025, 10026, 10027, 10028, 10029, 10030, 10031, 10032, 10033, 10034, 10035, 10036, 10037, 10038, 10039, 10040, 10041, 10042, 10043, 10044, 10045, 10046, 10047, 10048, 10049, 10050, 10051, 10052, 10053, 10054, 10055, 10056, 10057, 10058, 10059, 10060, 10061, 10062, 10063, 10064, 10065, 10066, 10067, 10068, 10069, 10070, 10071, 10072, 10073, 10074, 10075, 10076, 10077, 10078, 10079, 10080, 10081, 10082, 10083, 10084, 10085, 10086, 10087, 10088, 10089, 10090, 10091, 10092, 10093, 10094, 10095, 10096, 10097, 10098, 10099, 10100, 10101, 10102, 10103, 10104, 10105, 10106, 10107, 10108, 10109, 10110, 10111, 10112, 10113, 10114, 10115, 10116, 10117, 10118, 10119, 10120, 10121, 10122, 10123, 10124, 10125, 10126, 10127, 10128, 10129, 10130, 10131, 10132, 10133, 10134, 10135, 10136, 10137, 10138, 10139, 10140, 10141, 10142, 10143, 10144, 10145, 10146, 10147, 10148, 10149, 10150, 10151, 10152, 10153, 10154, 10155, 10156, 10157, 10158, 10159, 10160, 10161, 10162, 10163, 10164, 10165, 10166, 10167, 10168, 10169, 10170, 10171, 10172, 10173, 10174, 10175, 10176, 10177, 10178, 10179, 10180, 10181, 10182, 10183, 10184, 10185, 10186, 10187, 10188, 10189, 10190, 10191, 10192, 10193, 10194, 10195, 10196, 10197, 10198, 10199, 10200, 10201, 10202, 10203, 10204, 10205, 10206, 10207, 10208, 10209, 10210, 10211, 10212, 10213, 10214, 10215, 10216, 10217, 10218, 10219, 10220, 10221, 10222, 10223, 10224, 10225, 10226, 10227, 10228, 10229, 10230, 10231, 10232, 10233, 10234, 10235, 10236, 10237, 10238, 10239, 10240, 10241, 10242, 10243, 10244, 10245, 10246, 10247, 10248, 10249, 10250, 10251, 10252, 10253, 10254, 10255, 10256, 10257, 10258, 10259, 10260, 10261, 10262, 10263, 10264, 10265, 10266, 10267, 10268, 10269, 10270, 10271, 10272, 10273, 10274, 10275, 10276, 10277, 10278, 10279, 10280, 10281, 10282, 10283, 10284, 10285, 10286, 10287, 10288, 10289, 10290, 10291, 10292, 10293, 10294, 10295, 10296, 10297, 10298, 10299, 10300, 10301, 10302, 10303, 10304, 10305, 10306, 10307, 10308, 10309, 10310, 10311, 10312, 10313, 10314, 10315, 10316, 10317, 10318, 10319, 10320, 10321, 10322, 10323, 10324, 10325, 10326, 10327, 10328, 10329, 10330, 10331, 10332, 10333, 10380, 10381], [43, 44, 45, 46, 47, 85, 86, 87, 110, 111, 115, 157, 158, 159], [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 182, 183, 184, 185, 186, 187, 245, 246, 289, 290, 331, 332, 356, 357, 358, 359, 381, 382, 383, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 500, 501, 502, 503, 527, 528, 543, 544, 590, 591, 592, 593, 594, 621, 622, 651, 652, 653, 654, 655, 656, 657, 658, 659, 689, 690, 691, 692, 693, 694, 756, 757, 758, 759, 760, 802, 803, 846, 847, 867, 868, 879, 880, 881, 916, 917, 918, 919, 920, 921, 983, 984, 985, 986, 987, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1035, 1036, 1037, 1059, 1060, 1061, 1062, 1090, 1091, 1092, 1093, 1118, 1119, 1146, 1147, 1167, 1168, 1194, 1229, 1230, 1267, 1268, 1312, 1313, 1347, 1348, 1356, 1357, 1381, 1382, 1383, 1409, 1410, 1411, 1426, 1427, 1459, 1460, 1489, 1490, 1491, 1492, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1540, 1541, 1582, 1583, 1584, 1585, 1619, 1620, 1621, 1648, 1649, 1678, 1679, 1680, 1681, 1694, 1695, 1696, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1765, 1807, 1808, 1809, 1840, 1841, 1842, 1843, 1868, 1869, 1870, 1871, 1915, 1916, 1917, 1918, 1919, 1920, 1948, 1949, 1991, 1992, 2018, 2019, 2042, 2043, 2078, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2165, 2166, 2182, 2183, 2184, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2225, 2226, 2227, 2228, 2229, 2285, 2286, 2287, 2288, 2289, 2290, 2315, 2316, 2350, 2351, 2352, 2353, 2354, 2355, 2386, 2387, 2388, 2395, 2396, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2484, 2485, 2486, 2502, 2503, 2512, 2513, 2514, 2515, 2516, 2517, 2540, 2541, 2586, 2587, 2618, 2619, 2620, 2621, 2628, 2629, 2661, 2662, 2681, 2682, 2683, 2706, 2707, 2732, 2733, 2734, 2735, 2736, 2737, 2776, 2777, 2778, 2809, 2810, 2811, 2812, 2840, 2868, 2869, 2870, 2897, 2898, 2899, 2900, 2901, 2951, 2952, 2953, 2954, 2955, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3003, 3020, 3021, 3022, 3023, 3063, 3064, 3065, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3154, 3155, 3156, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3253, 3266, 3267, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3316, 3317, 3356, 3357, 3383, 3384, 3418, 3419, 3420, 3421, 3422, 3423, 3440, 3441, 3442, 3443, 3458, 3459, 3460, 3492, 3493, 3512, 3513, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3540, 3541, 3566, 3567, 3568, 3569, 3600, 3601, 3602, 3603, 3604, 3605, 3606, 3607, 3608, 3609, 3610, 3611, 3612, 3639, 3640, 3641, 3642, 3676, 3677, 3678, 3720, 3721, 3722, 3756, 3793, 3794, 3795, 3796, 3797, 3798, 3799, 3800, 3801, 3802, 3829, 3830, 3831, 3832, 3858, 3859, 3860, 3861, 3905, 3906, 3907, 3908, 3940, 3941, 3942, 3943, 3979, 3980, 3981, 3982, 3983, 3984, 3985, 4024, 4025, 4043, 4044, 4045, 4072, 4073, 4074, 4139, 4140, 4167, 4168, 4169, 4205, 4206, 4207, 4208, 4240, 4241, 4305, 4306, 4307, 4308, 4309, 4336, 4337, 4338, 4352, 4353, 4407, 4408, 4475, 4476, 4477, 4478, 4479, 4501, 4502, 4527, 4528, 4529, 4530, 4531, 4560, 4561, 4575, 4576, 4586, 4602, 4603, 4604, 4627, 4628, 4643, 4644, 4647]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aF[0][0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 285,
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130219/00/2013-02-19.00-06-00.bhvr',\n",
        " 1600,\n",
        " 0]"
       ]
      }
     ],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flattenedAF = flattenAnnotatedFrames(aF)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 330
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveConfusionMatrix(predict, testSet, fAF, baseDir='/tmp/cmat'):\n",
      "    folder = lambda l,p: os.path.join(baseDir, '{0}-{1}'.format(l,p))    \n",
      "    vE = videoExplorer.videoExplorer()\n",
      "    \n",
      "    size = len(testSet)\n",
      "    cmat = np.zeros((size, size))\n",
      "    \n",
      "    for i in range(size):\n",
      "        for k in range(size):\n",
      "            if not os.path.exists(folder(i,k)):\n",
      "                os.makedirs(folder(i,k))        \n",
      "             \n",
      "    k = 0\n",
      "    for l in range(len(testSet)):\n",
      "        for i in range(len(testSet[l])):\n",
      "            sample = testSet[l][i]\n",
      "            p = predict[k]\n",
      "            \n",
      "            fn = '{base}-v{vial}-f{frame}.png'.format(\\\n",
      "                    base=os.path.split(fAF[l][sample][0])[-1].split('.bhvr')[0],\n",
      "                    vial=fAF[l][sample][2],\n",
      "                    frame=fAF[l][sample][1])\n",
      "            savePath = os.path.join(folder(l,p), fn)\n",
      "            \n",
      "            videoPath = '{base}.v{vial}.avi'.format(\\\n",
      "                    base=fAF[l][sample][0].split('.bhvr')[0],\n",
      "                    vial=fAF[l][sample][2])\n",
      "            \n",
      "            saveFrameTo(vE, videoPath, fAF[l][sample][1], savePath, 'RGB')\n",
      "            \n",
      "            \n",
      "            cmat[l, p] += 1\n",
      "            \n",
      "            k += 1\n",
      "        \n",
      "    return cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 334
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "from ffvideo import VideoStream\n",
      "def saveFrameTo(self, videoPath, frameNo, filePath, frameMode='L'):\n",
      "    import scipy\n",
      "    frames = []\n",
      "    self.vs = VideoStream(videoPath, frame_mode=frameMode)      \n",
      "    for i in range(-1,2):\n",
      "        try:\n",
      "            frames += [np.rot90(self.vs.get_frame_no(frameNo + i).ndarray())]\n",
      "        except:\n",
      "            pass\n",
      "        \n",
      "    frame = np.concatenate(tuple(frames), axis=1)    \n",
      "    scipy.misc.imsave(filePath, frame)\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 352
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flattenedAF[0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 333,
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130219/00/2013-02-19.00-06-00.bhvr',\n",
        " 1597,\n",
        " 0]"
       ]
      }
     ],
     "prompt_number": 333
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(testSets)):\n",
      "    saveConfusionMatrix(predict[i], testSets[i], flattenedAF)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 360
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.arange(9).reshape((3,3))\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 1 2]\n",
        " [3 4 5]\n",
        " [6 7 8]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 344
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.rot90(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 346,
       "text": [
        "array([[2, 5, 8],\n",
        "       [1, 4, 7],\n",
        "       [0, 3, 6]])"
       ]
      }
     ],
     "prompt_number": 346
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rngS = np.random.permutation(range(featS.shape[0]))[:181]\n",
      "# rngD = np.random.permutation(range(featD.shape[0]))[:181]\n",
      "\n",
      "feat = np.concatenate(tuple([\\\n",
      "                            featS,\n",
      "                            featF,\n",
      "                            featD]))\n",
      "\n",
      "labels = np.concatenate(tuple([\\\n",
      "                              [0] * featS.shape[0],\n",
      "                              [1] * featF.shape[0],\n",
      "                              [2] * featD.shape[0]]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import grid_search\n",
      "\n",
      "c = RandomForestClassifier(n_jobs=6, criterion='entropy')\n",
      "# c = RandomForestClassifier(n_estimators=50, max_depth=30, n_jobs=6)\n",
      "\n",
      "parameters = {'n_estimators':[1,5,10,20,50,70,100,125,150,175,200,225], 'max_depth':[1, 10,20,30,40,50,60,70,80,90]}\n",
      "\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "\n",
      "clf = grid_search.GridSearchCV(c, parameters)\n",
      "clf.fit(feat, labels)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='entropy', max_depth=None, max_features='auto',\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=10, n_jobs=6, oob_score=False, random_state=None,\n",
        "            verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 5, 10, 20, 50, 70, 100, 125, 150, 175, 200, 225], 'max_depth': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='entropy', max_depth=90, max_features='auto',\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=150, n_jobs=6, oob_score=False, random_state=None,\n",
        "            verbose=0)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "c = RandomForestClassifier(n_estimators=150, max_depth=90, n_jobs=6, criterion='gini')\n",
      "\n",
      "\n",
      "cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[173   8   0]\n",
        " [  1 174   6]\n",
        " [  6  13 162]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# c.fit(feat, labels)\n",
      "\n",
      "rngST = list(set(range(featS.shape[0])).difference(rngS))\n",
      "rngDT = list(set(range(featD.shape[0])).difference(rngD))\n",
      "    \n",
      "featT = np.concatenate(tuple([\\\n",
      "                            featS[rngST],\n",
      "                            featD[rngDT]]))\n",
      "\n",
      "labelsT = np.concatenate(tuple([\\\n",
      "                              [0] * len(rngST),\n",
      "                              [2] * len(rngDT)]))\n",
      "\n",
      "plabels = c.predict(featT)\n",
      "computeConfusionMatrix(plabels, labelsT)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "array([[ 9843.,   282.,    93.],\n",
        "       [    0.,     0.,     0.],\n",
        "       [  129.,   376.,  3962.]])"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances = c.feature_importances_\n",
      "std = np.std([tree.feature_importances_ for tree in c.estimators_],\n",
      "             axis=0)\n",
      "indices = np.argsort(importances)[::-1][:10]\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(10):\n",
      "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
      "\n",
      "# Plot the feature importances of the forest\n",
      "import pylab as pl\n",
      "pl.figure()\n",
      "pl.title(\"Feature importances\")\n",
      "pl.bar(range(10), importances[indices],\n",
      "       color=\"r\", yerr=std[indices], align=\"center\")\n",
      "pl.xticks(range(10), indices)\n",
      "pl.xlim([-1, 10])\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature ranking:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1. feature 325 (0.018451)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2. feature 620 (0.017953)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3. feature 17 (0.015485)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4. feature 1010 (0.014643)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5. feature 781 (0.014251)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6. feature 356 (0.014045)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7. feature 340 (0.010098)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8. feature 1023 (0.009829)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9. feature 33 (0.009811)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10. feature 151 (0.009515)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argsort(importances)[::-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([325, 620,  17, ...,   0, 116, 321])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn import svm\n",
      "\n",
      "\n",
      "# c = svm.SVC()\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.ensemble import AdaBoostClassifier\n",
      "# from sklearn import svm\n",
      "# from sklearn.linear_model import SGDClassifier\n",
      "# from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "# base = c#MultinomialNB()\n",
      "# ada = AdaBoostClassifier(base_estimator=base)\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, ada,  Nfolds=10)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[10359     2    38]\n",
        " [   30    55    96]\n",
        " [   86     0  4562]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = set(range(featS.shape[0])).difference(rngS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "10218"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featS.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "10399"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%qtconsole"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = time.localtime()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.tmm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}