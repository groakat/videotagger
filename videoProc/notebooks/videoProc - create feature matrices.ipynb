{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "import os\n",
      "import pyTools.videoProc.annotation as annotation\n",
      "import pyTools.system.videoExplorer as videoExplorer\n",
      "import pyTools.misc.config as cfg\n",
      "import pyTools.misc.basic as bsc\n",
      "import time\n",
      "import operator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataFolder = '/run/media/peter/Elements/peter/data/tmp-20130506'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "behaviour = \"struggling\"\n",
      "annotator = \"peter\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractAnnotatedFrames(vials=None, annotator=\"peter\", behaviour=\"struggling\", \n",
      "                           dataFolder='/run/media/peter/Elements/peter/data/tmp-20130506'):\n",
      "    \n",
      "    filt = annotation.AnnotationFilter(vials, [annotator], [behaviour])\n",
      "#     frames = []\n",
      "    \n",
      "    # list of filtered frames (one list for each vial)\n",
      "    a = [[] for i in range(4)]\n",
      "    \n",
      "    for root, dirs, files in os.walk(dataFolder):\n",
      "        for file in files:\n",
      "            if file.endswith(\".bhvr\"):\n",
      "                # load annotation and filter it #\n",
      "                path = os.path.join(root,file)\n",
      "                anno = annotation.Annotation()\n",
      "        \n",
      "                anno.loadFromFile(path)\n",
      "                filteredAnno = anno.filterFrameList(filt)\n",
      "                \n",
      "                if behaviour in anno.behaviours and annotator in anno.annotators:\n",
      "                    # extract frame numbers corresponding to filter #\n",
      "                    frameList = [[i, x] for i, x in enumerate(filteredAnno.frameList)  \\\n",
      "                                             if x is not None]\n",
      "                    \n",
      "                    # sort frames into the different vials to know what\n",
      "                    # feature files we will have to load later #\n",
      "                    if frameList:\n",
      "                        for f in frameList:\n",
      "#                             frames += [[path, f[0]]]\n",
      "                            for v in range(len(a)):\n",
      "                                if f[1][v] is not None:\n",
      "                                    a[v] += [[path.split('.bhvr')[0] + '.pos.npy', f[0]]]\n",
      "                    \n",
      "    return a\n",
      "\n",
      "def extractNegativeAnnotatedFrames(vials=None, annotator=\"peter\", behaviours=[\"struggling\"], \n",
      "                           dataFolder='/run/media/peter/Elements/peter/data/tmp-20130506',\n",
      "                           samplesNo=10000):\n",
      "    \"\"\"\n",
      "    Extracts frames that do not contain any of the given behaviours.\n",
      "    \n",
      "    The algorithm samples frames randomly from the given `dataFolder` and verifies that they\n",
      "    are not labelled with the given annotations\n",
      "    \n",
      "    TODO: needs refinement in vial selection\n",
      "    \"\"\"\n",
      "#     frames = []\n",
      "    noVials = 3\n",
      "    \n",
      "    # list of filtered frames (one list for each vial)\n",
      "    a = [[] for i in range(3)]\n",
      "    \n",
      "    fileList = []\n",
      "    for root, dirs, files in os.walk(dataFolder):\n",
      "        for file in files:\n",
      "            if file.endswith(\".bhvr\"):\n",
      "                fileList += [os.path.join(root,file)]\n",
      "                \n",
      "    fileList.sort() \n",
      "    \n",
      "    for i in range(samplesNo):\n",
      "        # random selection of file (not the first or last one because some features\n",
      "        # might not be extracted for them)\n",
      "        fileIdx = int(np.floor(np.random.random() * (len(fileList) - 2))) + 1\n",
      "        # random selection of vial\n",
      "        vIdx = int(np.floor(np.random.random() * noVials))\n",
      "        \n",
      "        # load annotation and filter it #\n",
      "        path = os.path.join(fileList[fileIdx])\n",
      "        anno = annotation.Annotation()\n",
      "        anno.loadFromFile(path)\n",
      "        \n",
      "        # random selection of frame\n",
      "        negativeFrames = range(len(anno.frameList))\n",
      "        for behaviour in behaviours:\n",
      "            annoFrames = anno.getFramesWithBehaviour(behaviour, [vIdx])\n",
      "            negativeFrames = set(negativeFrames).difference(annoFrames)\n",
      "            \n",
      "        if not negativeFrames:\n",
      "            # if we get here, that means that all frames\n",
      "            # in the given vial are annotated by the behaviour\n",
      "            i -= 1\n",
      "            continue\n",
      "        else:\n",
      "            selFrameIdx = np.random.permutation(list(negativeFrames))[0]\n",
      "            a[vIdx] += [[path.split('.bhvr')[0] + '.pos.npy', selFrameIdx]]\n",
      "        \n",
      "        \n",
      "                    \n",
      "    return a\n",
      "                    \n",
      "\n",
      "       \n",
      "# cfg.log.info(\"finished in {0} sec\".format(time.time() - t))   \n",
      "\n",
      "def createFeatureVector(a, ending=['feat.hog3d']):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        a (list [[path, int]]):\n",
      "                    list of paths with corresponding\n",
      "                    frame numbers\n",
      "                    see :func:`extractAnnotatedFrames`\n",
      "    \"\"\"\n",
      "    # feature matrix #\n",
      "    feats = []\n",
      "    for i in range(len(a)):\n",
      "        # path to feature vector #\n",
      "        path = ''\n",
      "        # numpy array containing features #\n",
      "        npA = [None for k in range(len(ending))]\n",
      "        for frame in a[i]:            \n",
      "            if frame[0] != path:\n",
      "                # load new feature vector only if it was not used already before #\n",
      "                path = frame[0]\n",
      "                for k in range(len(ending)):\n",
      "                    npA[k] = np.load(path.split('.pos.npy')[0] + \\\n",
      "                                     '.v{0}.{ending}.npy'.format(i, ending=ending[k]))\n",
      "            f = []\n",
      "            try:\n",
      "                for k in range(len(ending)):\n",
      "                    f += [npA[k][frame[1]].flatten()]\n",
      "            except:\n",
      "                print(\"Problems loading {0}\".format(frame))\n",
      "                \n",
      "            feats += [np.concatenate(tuple(f))]\n",
      "            \n",
      "    return np.asarray(feats)\n",
      "\n",
      "def createFeatureVectorFromAnnotationSections(aS, ending=['feat.hog3d']):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        a (list [[path, int]]):\n",
      "                    list of paths with corresponding\n",
      "                    frame numbers\n",
      "                    see :func:`extractAnnotatedFrames`\n",
      "    \"\"\"\n",
      "    # feature matrix #\n",
      "    feats = []\n",
      "    aCnt = 0\n",
      "    for a in aS:\n",
      "        aCnt += 1\n",
      "        # path to feature vector #\n",
      "        path = ''\n",
      "        vial = -1\n",
      "        # numpy array containing features #\n",
      "        npA = [None for k in range(len(ending))]\n",
      "        featSs = []\n",
      "        \n",
      "        sCnt = 0\n",
      "        for section in a:            \n",
      "            sCnt += 1\n",
      "            featFs = []\n",
      "            for frame in section:\n",
      "                if frame[0] != path or frame[2] != vial:\n",
      "                    # load new feature vector only if it was not used already before #\n",
      "                    path = copy.copy(frame[0])\n",
      "                    vial = frame[2]\n",
      "                    for k in range(len(ending)):\n",
      "                        npA[k] = np.load(path.split('.pos.npy')[0] + \\\n",
      "                                         '.v{0}.{ending}.npy'.format(vial, ending=ending[k]))\n",
      "                f = []\n",
      "                try:\n",
      "                    for k in range(len(ending)):\n",
      "                        f += [npA[k][frame[1]].flatten()]\n",
      "                except:\n",
      "                    print(\"Problems loading {0}\".format(frame))\n",
      "                \n",
      "                featFs += [np.concatenate(tuple(f))]\n",
      "            \n",
      "            feat = np.asarray(featFs)\n",
      "            if feat.shape == (0,):\n",
      "                print frame\n",
      "                \n",
      "            featSs += [feat]\n",
      "        \n",
      "        feats += [featSs]        \n",
      "                \n",
      "            \n",
      "    return feats\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeConfusionMatrix(predict, label):\n",
      "    size = np.max(label) + 1\n",
      "    cmat = np.zeros((size, size))\n",
      "    \n",
      "    for i in range(predict.shape[0]):\n",
      "        cmat[label[i], predict[i]] += 1\n",
      "        \n",
      "    return cmat\n",
      "\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "def crossValidateIndependentSamples(data, labels, classifier, Nfolds=2):\n",
      "    idx = np.unique(labels)\n",
      "    cmat = np.zeros((idx.shape[0], idx.shape[0]), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(labels, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    for train, test in kf:\n",
      "        testPos.append(test)\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        trainSet = data[train]\n",
      "        trainLbl = labels[train]\n",
      "        \n",
      "        testSet = data[test]\n",
      "        testLbl.append(labels[test])\n",
      "        \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, testLbl, testPos\n",
      "\n",
      "def crossValidateSampleSets(data, labels, sets, classifier, Nfolds=2):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        data (list of np.arrays)\n",
      "                list of feature matrices, one for each class\n",
      "        labels (list of np.arrays)\n",
      "                list of labels corresponding feature matrices in data\n",
      "        sets (list of [begin (int), end (int)])\n",
      "                list of indeces of sets of groups of samples in feature\n",
      "                matrices\n",
      "                \n",
      "                \n",
      "    \"\"\"\n",
      "    \n",
      "    # construct pseudo feature matrix that in reality contains \n",
      "    # indices to sections in the sets, which will then be used\n",
      "    # to sample from the samples within the choosen sections\n",
      "    # to create unbiased training and test set\n",
      "    \n",
      "    pseudoFeat = np.asarray([f for s in sets for f in range(len(s))])\n",
      "    pseudoLabel = np.asarray([i for i in range(len(sets)) for f in range(len(sets[i]))])\n",
      "    \n",
      "    idx = np.max(pseudoLabel) + 1\n",
      "    cmat = np.zeros((idx, idx), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(pseudoLabel, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    trainSets = []\n",
      "    testSets = []\n",
      "    \n",
      "    for train, test in kf:\n",
      "        testPos.append(test)\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        \n",
      "        # create balanced training set\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            cFeat += [[i for t in train \\\n",
      "                           if pseudoLabel[t] == c \\\n",
      "                               for i in range(*sets[pseudoLabel[t]][pseudoFeat[t]])]]\n",
      "            \n",
      "        maxSamples = min([len(a) for a in cFeat])\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        selection = []\n",
      "        for c in range(len(cFeat)):\n",
      "            idces = np.random.permutation(np.asarray(cFeat[c]))[:maxSamples]\n",
      "            feats += [data[c][idces]]\n",
      "            lbls += [[c] * maxSamples]\n",
      "            selection += [idces]\n",
      "            \n",
      "                \n",
      "        trainSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        trainSets += [selection]\n",
      "        trainLbl = np.concatenate(tuple(lbls)) #labels[train]\n",
      "        \n",
      "        \n",
      "        # create test set from all samples in sets choosen for testing\n",
      "        # (class imbalance does not matter)\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            cFeat += [[i for t in test \\\n",
      "                           if pseudoLabel[t] == c \\\n",
      "                               for i in range(*sets[pseudoLabel[t]][pseudoFeat[t]])]]\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        for c in range(len(cFeat)):\n",
      "            feats += [data[c][cFeat[c]]]\n",
      "            lbls += [[c] * len(cFeat[c])]\n",
      "            \n",
      "                \n",
      "        testSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        testSets += [cFeat]\n",
      "        testLbl.append(np.concatenate(tuple(lbls))) #labels[train]\n",
      "        \n",
      "        \n",
      "        # train classifier and test \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, trainSets, testSets\n",
      "\n",
      "\n",
      "def getPseudoIndeces(sets):    \n",
      "    # construct pseudo feature matrix that in reality contains \n",
      "    # indices to sections in the sets, which will then be used\n",
      "    # to sample from the samples within the choosen sections\n",
      "    # to create unbiased training and test set\n",
      "    pseudoFeat = np.asarray([f for s in sets for f in range(len(s))])\n",
      "    pseudoLabel = np.asarray([i for i in range(len(sets)) for f in range(len(sets[i]))])\n",
      "    \n",
      "    return pseudoFeat, pseudoLabel\n",
      "\n",
      "def crossValidateSectionSets(sets, classifier, Nfolds=2):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "        data (list of np.arrays)\n",
      "                list of feature matrices, one for each class\n",
      "        labels (list of np.arrays)\n",
      "                list of labels corresponding feature matrices in data\n",
      "        sets (list of [begin (int), end (int)])\n",
      "                list of indeces of sets of groups of samples in feature\n",
      "                matrices\n",
      "                \n",
      "                \n",
      "    \"\"\"\n",
      "    \n",
      "    # construct pseudo feature matrix that in reality contains \n",
      "    # indices to sections in the sets, which will then be used\n",
      "    # to sample from the samples within the choosen sections\n",
      "    # to create unbiased training and test set\n",
      "    \n",
      "#     pseudoFeat = np.asarray([f for s in sets for f in range(len(s))])\n",
      "#     pseudoLabel = np.asarray([i for i in range(len(sets)) for f in range(len(sets[i]))])\n",
      "    \n",
      "    pseudoFeat, pseudoLabel = getPseudoIndeces(sets)\n",
      "    \n",
      "    idx = np.max(pseudoLabel) + 1\n",
      "    cmat = np.zeros((idx, idx), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(pseudoLabel, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    trainSets = []\n",
      "    testSets = []\n",
      "    selectionSet = []\n",
      "    \n",
      "    for train, test in kf:\n",
      "        trainSets += [train]\n",
      "        testSets += [test]\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        \n",
      "        # create balanced training set\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            abc = [sets[pseudoLabel[t]][pseudoFeat[t]] \\\n",
      "                                               for t in train \\\n",
      "                                                   if pseudoLabel[t] == c ]\n",
      "#             for a in abc:\n",
      "#                 print a.shape\n",
      "            cFeat += [np.concatenate(abc)]\n",
      "        \n",
      "        \n",
      "        maxSamples = min([a.shape[0] for a in cFeat])\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        selection = []\n",
      "        for c in range(len(cFeat)):\n",
      "            idces = np.random.permutation(np.arange(cFeat[c].shape[0]))[:maxSamples]\n",
      "            feats += [cFeat[c][idces]]\n",
      "            lbls += [[c] * maxSamples]\n",
      "            selection += [idces]\n",
      "            \n",
      "                \n",
      "        trainSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        selectionSet += [selection]\n",
      "        trainLbl = np.concatenate(tuple(lbls)) #labels[train]\n",
      "        \n",
      "        \n",
      "        # create test set from all samples in sets choosen for testing\n",
      "        # (class imbalance does not matter)\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            cFeat += [np.concatenate(tuple([sets[pseudoLabel[t]][pseudoFeat[t]] \\\n",
      "                                               for t in test \\\n",
      "                                                   if pseudoLabel[t] == c ]))]\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        for c in range(len(cFeat)):\n",
      "            feats += [cFeat[c]]\n",
      "            lbls += [[c] * cFeat[c].shape[0]]\n",
      "            \n",
      "                \n",
      "        testSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        testLbl.append(np.concatenate(tuple(lbls))) #labels[train]\n",
      "        \n",
      "        \n",
      "        # train classifier and test \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        cmat += computeConfusionMatrix(predict[-1], testLbl[-1])\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, trainSets, testSets, selectionSet\n",
      "\n",
      "def crossValidateSectionSetsMIL(sets, classifier, additionalFrames=100, negativeSet=1, Nfolds=2, verbose=True):\n",
      "    \"\"\"\n",
      "    \n",
      "    Takes only one-vs-all type of multi-class\n",
      "    \n",
      "    Args:\n",
      "        negativeSets (int):\n",
      "                set with only negative examples\n",
      "        data (list of np.arrays)\n",
      "                list of feature matrices, one for each class\n",
      "        labels (list of np.arrays)\n",
      "                list of labels corresponding feature matrices in data\n",
      "        sets (list of [begin (int), end (int)])\n",
      "                list of indeces of sets of groups of samples in feature\n",
      "                matrices\n",
      "                \n",
      "                \n",
      "    \"\"\"\n",
      "    \n",
      "    # construct pseudo feature matrix that in reality contains \n",
      "    # indices to sections in the sets, which will then be used\n",
      "    # to sample from the samples within the choosen sections\n",
      "    # to create unbiased training and test set\n",
      "    \n",
      "#     pseudoFeat = np.asarray([f for s in sets for f in range(len(s))])\n",
      "#     pseudoLabel = np.asarray([i for i in range(len(sets)) for f in range(len(sets[i]))])\n",
      "    \n",
      "    pseudoFeat, pseudoLabel = getPseudoIndeces(sets)\n",
      "    \n",
      "    idx = np.max(pseudoLabel) + 1\n",
      "    cmat = np.zeros((idx, idx), dtype=np.int32)\n",
      "    \n",
      "    #kf = KFold(len(labels), n_folds=Nfolds, indices=True)\n",
      "    kf = StratifiedKFold(pseudoLabel, n_folds=Nfolds, indices=True)\n",
      "    \n",
      "    cnt = 1\n",
      "    \n",
      "    predict = []\n",
      "    testLbl = []\n",
      "    testPos = []\n",
      "    trainSets = []\n",
      "    testSets = []\n",
      "    selectionSet = []\n",
      "    \n",
      "    for train, test in kf:\n",
      "        trainSets += [train]\n",
      "        testSets += [test]\n",
      "        print(\"processing fold no {0}/{1}\".format(cnt, Nfolds))\n",
      "        \n",
      "        \n",
      "        # create balanced training set\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            abc = [sets[pseudoLabel[t]][pseudoFeat[t]] \\\n",
      "                                               for t in train \\\n",
      "                                                   if pseudoLabel[t] == c ]\n",
      "#             for a in abc:\n",
      "#                 print a.shape\n",
      "            cFeat += [np.concatenate(abc)]\n",
      "        \n",
      "        \n",
      "        maxSamples = min([a.shape[0] for a in cFeat])\n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        selection = []\n",
      "        for c in range(len(cFeat)):\n",
      "            idces = np.random.permutation(np.arange(cFeat[c].shape[0]))[:maxSamples]\n",
      "            feats += [cFeat[c][idces]]\n",
      "            lbls += [[c] * maxSamples]\n",
      "            selection += [idces]\n",
      "            \n",
      "                \n",
      "        trainSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        selectionSet += [selection]\n",
      "        trainLbl = np.concatenate(tuple(lbls)) #labels[train]\n",
      "        \n",
      "        \n",
      "        # create test set from all samples in sets choosen for testing\n",
      "        # (class imbalance does not matter)\n",
      "        cFeat = []\n",
      "        for c in range(idx):\n",
      "            if c == negativeSet:\n",
      "                cFeat += [np.concatenate(tuple([sets[pseudoLabel[t]][pseudoFeat[t]] \\\n",
      "                                                   for t in test \\\n",
      "                                                       if pseudoLabel[t] == c ]))]\n",
      "            else:\n",
      "                pI = lambda bag: extractPositiveInstances(bag, additionalFrames)\n",
      "                cFeat += [np.concatenate(tuple([pI(sets[pseudoLabel[t]][pseudoFeat[t]]) \\\n",
      "                                                   for t in test \\\n",
      "                                                       if pseudoLabel[t] == c ]))]\n",
      "                \n",
      "        \n",
      "        feats = []\n",
      "        lbls= []\n",
      "        for c in range(len(cFeat)):\n",
      "            feats += [cFeat[c]]\n",
      "            lbls += [[c] * cFeat[c].shape[0]]\n",
      "            \n",
      "                \n",
      "        testSet = np.concatenate(tuple(feats)) #data[train]\n",
      "        testLbl.append(np.concatenate(tuple(lbls))) #labels[train]\n",
      "        \n",
      "        \n",
      "        # train classifier and test \n",
      "        wclf = classifier\n",
      "        wclf.fit(trainSet, trainLbl)\n",
      "        \n",
      "        predict.append(wclf.predict(testSet))\n",
      "        \n",
      "        curCMAT = computeConfusionMatrix(np.int32(predict[-1] > 0), testLbl[-1])\n",
      "        cmat += curCMAT\n",
      "        if verbose:\n",
      "            print curCMAT\n",
      "        cnt += 1\n",
      "    \n",
      "    return cmat, predict, trainSets, testSets, selectionSet\n",
      "\n",
      "def getMissClassified(predict, labels, pathList, cl):\n",
      "    out = []\n",
      "    \n",
      "    for i in range(len(pathList)):\n",
      "        if predict[i] != labels[i] and labels[i] == cl:\n",
      "            out.append(pathList[i])\n",
      "            \n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "aF = []\n",
      "aF += [extractAnnotatedFrames(behaviour=\"falling\")]\n",
      "aF += [extractAnnotatedFrames(behaviour=\"dropping\")]\n",
      "aF += [extractAnnotatedFrames(behaviour=\"struggling\")]\n",
      "aF += [extractNegativeAnnotatedFrames(behaviours=[\"falling\", \"dropping\", \"struggling\"])]\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-28 12:42:00,311 \u001b[0m[T: 139818498742080] \u001b[33m<<module>> \u001b[39m[7] \u001b[1mfinished in 445.146869183 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 445.146869183 sec\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import deque\n",
      "import copy\n",
      "\n",
      "def extractContinuousAnnotationSections(aF, fileList):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "    \n",
      "    \n",
      "    Returns:\n",
      "        list of list with [begin, end] of sections of continuous appearances\n",
      "        of a label.\n",
      "        `begin` and `end` are as it is required to generate a valid slice\n",
      "        with range(begin, end)\n",
      "\n",
      "    \"\"\"\n",
      "    sect = []#[] for i in range(len(aF))]\n",
      "    for b in range(len(aF)):\n",
      "        sect += [[]]\n",
      "        for v in range(len(aF[b])):\n",
      "            vSec = []\n",
      "            start = 0\n",
      "            end = None\n",
      "            for a in range(1, len(aF[b][v])):\n",
      "                if aF[b][v][a-1][0] ==  aF[b][v][a][0]:\n",
      "                    if aF[b][v][a-1][1] ==  aF[b][v][a][1] - 1:\n",
      "                        continue                        \n",
      "                    else:\n",
      "                        end = a                        \n",
      "                elif aF[b][v][a][1] == 0:\n",
      "                    \n",
      "                    if fileList.index(aF[b][v][a][0]) \\\n",
      "                    == fileList.index(aF[b][v][a - 1][0]) + 1:\n",
      "                        pos = np.load(aF[b][v][a - 1][0])\n",
      "                        if pos.shape[0] == aF[b][v][a - 1][1] + 1:\n",
      "                            print aF[b][v][a - 1]\n",
      "                            continue\n",
      "                        else:\n",
      "                            end = a\n",
      "                    else:\n",
      "                        end = a\n",
      "                else:\n",
      "                    end = a\n",
      "                    \n",
      "                if end is not None:\n",
      "                    vSec += [[start, end]]\n",
      "                    start = a\n",
      "                    end = None                    \n",
      "                    \n",
      "            vSec += [[start, a + 1]]        \n",
      "            sect[b] += [vSec]\n",
      "            \n",
      "    return sect\n",
      "\n",
      "\n",
      "def extendAnnotationSections(aF, sections, fileList, additionalFrames=0):\n",
      "    \"\"\"\n",
      "    Args:\n",
      "    \n",
      "    \n",
      "    Returns:\n",
      "        list of list with [begin, end] of sections of continuous appearances\n",
      "        of a label.\n",
      "        `begin` and `end` are as it is required to generate a valid slice\n",
      "        with range(begin, end)\n",
      "\n",
      "    \"\"\"\n",
      "    aS = []\n",
      "    \n",
      "    for a in range(len(sections)):\n",
      "        classSects = []\n",
      "        for v in range(len(sections[a])):\n",
      "            for s in range(len(sections[a][v])):\n",
      "                frameList = deque()\n",
      "                start = copy.copy(aF[a][v][sections[a][v][s][0]])\n",
      "                end = copy.copy(aF[a][v][sections[a][v][s][1] - 1])\n",
      "                \n",
      "                remainingFrames = additionalFrames\n",
      "                \n",
      "                while remainingFrames > 0:                 \n",
      "                    remainingFrames -= 1\n",
      "                    start[1] -= 1                    \n",
      "                    if start[1] < 0:\n",
      "                        filePos = fileList.index(start[0])\n",
      "                        if filePos < 1:\n",
      "                            cfg.log.warning(\\\n",
      "                            'tried to include frames previous to the first frame {0} {1} {2}'.format(a,v,s))\n",
      "                            break\n",
      "                        start[0] = fileList[filePos - 1]\n",
      "                        start[1] = np.load(start[0]).shape[0] - 1\n",
      "                        \n",
      "                    frameList.appendleft(copy.copy(start) + [v])   \n",
      "\n",
      "                \n",
      "                for i in range(*sections[a][v][s]):\n",
      "                    frameList.append(copy.copy(aF[a][v][i]) + [v])\n",
      "                \n",
      "                curLength = np.load(end[0]).shape[0]\n",
      "                remainingFrames = additionalFrames\n",
      "                \n",
      "                \n",
      "                while remainingFrames > 0:               \n",
      "                    remainingFrames -= 1\n",
      "                    end[1] += 1\n",
      "                    \n",
      "                    if end[1] >= curLength:\n",
      "                        filePos = fileList.index(end[0])\n",
      "                        if filePos >= len(fileList) - 1:\n",
      "                            cfg.log.warning(\\\n",
      "                            'tried to include frames after to the last frame {0} {1} {2}'.format(a,v,s))\n",
      "                            break\n",
      "                        end[0] = fileList[filePos + 1]\n",
      "                        curLength = np.load(end[0]).shape[0]\n",
      "                        end[1] = 0\n",
      "                        \n",
      "                    frameList.append(copy.copy(end) + [v])     \n",
      "                        \n",
      "                if len(frameList) == 0:\n",
      "                    print a,v,sections[a][v]\n",
      "                    \n",
      "                classSects += [frameList]\n",
      "                \n",
      "        aS += [classSects]\n",
      "                            \n",
      "    return aS\n",
      "\n",
      "\n",
      "def flattenAnnotationSections(sect):\n",
      "    out = []\n",
      "    \n",
      "    for a in range(len(sect)):\n",
      "        aSec = []\n",
      "        offSet = 0\n",
      "        for v in range(len(sect[a])):\n",
      "            for i in range(len(sect[a][v])):\n",
      "                aSec += [[sect[a][v][i][0] + offSet, sect[a][v][i][1] + offSet]]\n",
      "            \n",
      "            offSet = aSec[-1][1]\n",
      "            \n",
      "        out += [aSec]\n",
      "        \n",
      "    return out\n",
      "\n",
      "def providePosList(path):\n",
      "    fileList  = []\n",
      "    posList = []\n",
      "    print(\"scaning files...\")\n",
      "    for root,  dirs,  files in os.walk(path):\n",
      "        for f in files:\n",
      "            if f.endswith('pos.npy'):\n",
      "                path = root + '/' + f\n",
      "                fileList.append(path)\n",
      "                \n",
      "    fileList = sorted(fileList)\n",
      "    print(\"scaning files done\")\n",
      "    return fileList\n",
      "\n",
      "def flattenAnnotatedFrames(aF):\n",
      "    flattenedAF = []\n",
      "    for a in aF:     \n",
      "        aList = []\n",
      "        for v in range(len(a)):\n",
      "            aList += [i + [v] for i in a[v]]\n",
      "        flattenedAF += [aList]\n",
      "        \n",
      "    return flattenedAF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileList = providePosList(dataFolder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "scaning files..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "scaning files done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sect = extractContinuousAnnotationSections(aF, fileList)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/20/2013-02-20.20-38-00.pos.npy', 875]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130220/21/2013-02-20.21-11-00.pos.npy', 875]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aS = []\n",
      "additionalFrames = 1000\n",
      "s = sect[0:3]\n",
      "aS += extendAnnotationSections(aF[0:3], s, fileList, additionalFrames)\n",
      "aS += extendAnnotationSections([aF[3]], [sect[3]], fileList, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mWARNING\u001b[49m \u001b[1m2013-09-28 15:20:22,655 \u001b[0m[T: 139818498742080] \u001b[33m<extendAnnotationSections> \u001b[39m[84] \u001b[1mtried to include frames previous to the first frame 1 0 0\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:log:tried to include frames previous to the first frame 1 0 0\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sortKey(x):\n",
      "    op = operator.itemgetter(0,2)\n",
      "    return op(x[0])\n",
      "\n",
      "# if aS[3] is sorted (first path then vialno), the feature import (next step will hopefully be faster)\n",
      "aS[3] = sorted(aS[3], key=sortKey)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%qtconsole"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "# ending = ['feat.hog3d', 'feat.hog3d-xy2-t0.5', 'feat.hog3d-xy1-t0.25', 'feat.hog3d-xy2-t0.25', 'feat.hog-8', 'feat.position']\n",
      "ending = ['feat.hog3d', 'feat.position']\n",
      "# ending = ['feat.hog3d-xy2-t0.5']\n",
      "feat = createFeatureVectorFromAnnotationSections(aS, ending=ending)\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-28 15:34:23,697 \u001b[0m[T: 139818498742080] \u001b[33m<<module>> \u001b[39m[6] \u001b[1mfinished in 745.398536921 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 745.398536921 sec\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveMILData(data, additionalFrames=100, negBags=50):\n",
      "    \"\"\"\n",
      "    data[0] is the positive class\n",
      "    data[1] is the negative class    \n",
      "    \n",
      "    output format will be\n",
      "    \n",
      "    instance name (just a running integer), bag name (ID), instance label (0/1), features\n",
      "    \"\"\"\n",
      "    aF = additionalFrames\n",
      "    \n",
      "    id = 0\n",
      "    bagList = []\n",
      "    # process posivite bags\n",
      "    for bP in range(len(data[0])):\n",
      "        negIID1 = np.arange(id, id+aF).reshape(aF,1)\n",
      "        id += aF\n",
      "        bagID1 = np.zeros((aF,1)) + bP   \n",
      "        lbl = np.zeros((aF,1))\n",
      "        negFeat1 = data[0][bP][:aF]    \n",
      "        negPt1 = np.hstack((negIID1, bagID1, lbl, negFeat1))\n",
      "    \n",
      "        noPos = data[0][bP].shape[0] - 2 * aF\n",
      "        posID = np.arange(id, id + noPos).reshape(noPos,1)\n",
      "        id += noPos\n",
      "        bagID2 = np.zeros((noPos,1)) + bP    \n",
      "        lbl = np.ones((noPos,1))\n",
      "        posFeat1 = data[0][bP][aF:-aF]\n",
      "        posPt = np.hstack((posID, bagID2, lbl, posFeat1))\n",
      "        \n",
      "        negIID2 = np.arange(id, id+aF).reshape(aF,1)\n",
      "        id += aF\n",
      "        bagID3 = np.zeros((aF,1)) + bP\n",
      "        lbl =  np.zeros((aF,1))\n",
      "        negFeat2 = data[0][bP][-aF:] \n",
      "        negPt2 = np.hstack((negIID2,bagID3, lbl, negFeat2))\n",
      "        \n",
      "        bagList += [np.vstack((negPt1, posPt, negPt2))]\n",
      "        \n",
      "        \n",
      "    bagID = bP\n",
      "    for bag in partition(data[1], negBags):\n",
      "        noInst = len(bag)\n",
      "        \n",
      "        ids = np.arange(id, id+noInst).reshape(noInst,1)\n",
      "        id += noInst\n",
      "        \n",
      "        bagIDs = np.zeros((noInst,1)) + bagID\n",
      "        bagID += 1\n",
      "         \n",
      "        lbl =  np.zeros((noInst,1))\n",
      "        \n",
      "        feats = np.vstack(bag)\n",
      "        \n",
      "        bagList += [np.hstack((ids, bagIDs, lbl, feats))]\n",
      "        \n",
      "        \n",
      "    return np.vstack(bagList)\n",
      "\n",
      "def extractPositiveInstances(bag, additionalFrames=100):\n",
      "    return bag[additionalFrames:-additionalFrames]\n",
      "        \n",
      "        \n",
      "def partition ( lst, n ):\n",
      "    chunkSize = np.int32(np.ceil(len(lst) / np.float32(n)))\n",
      "    return bsc.chunks(lst, chunkSize)\n",
      "    \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "milData = saveMILData([feat[0], feat[3]], additionalFrames=additionalFrames)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveConfusionMatrix(predict, testSet, aS, baseDir='/tmp/cmat'):\n",
      "    folder = lambda l,p: os.path.join(baseDir, '{0}-{1}'.format(l,p))    \n",
      "    vE = videoExplorer.videoExplorer()\n",
      "    \n",
      "    pseudoFeat, pseudoLabel = getPseudoIndeces(aS)\n",
      "    \n",
      "    size = max(pseudoLabel) + 1\n",
      "    cmat = np.zeros((size, size))\n",
      "    \n",
      "    for i in range(size):\n",
      "        for k in range(size):\n",
      "            if not os.path.exists(folder(i,k)):\n",
      "                os.makedirs(folder(i,k))        \n",
      "             \n",
      "    \n",
      "    for test in range(len(testSet)):\n",
      "        k = 0\n",
      "        for t in testSet[test]:\n",
      "            l = pseudoLabel[t]\n",
      "            section = aS[l][pseudoFeat[t]]\n",
      "            for f in section:\n",
      "                basePath = f[0].split('.pos.npy')[0]\n",
      "                frameNo = f[1]\n",
      "                vialNo = f[2]\n",
      "                p = predict[test][k]\n",
      "             \n",
      "                fn = '{base}-v{vial}-f{frame}.png'.format(\\\n",
      "                        base=os.path.split(basePath)[-1],\n",
      "                        vial=vialNo,\n",
      "                        frame=frameNo)\n",
      "                savePath = os.path.join(folder(l,p), fn)\n",
      "                \n",
      "                videoPath = '{base}.v{vial}.avi'.format(\\\n",
      "                        base=basePath,\n",
      "                        vial=vialNo)\n",
      "                \n",
      "                saveFrameTo(vE, videoPath, frameNo, savePath, 'RGB')\n",
      "                \n",
      "                \n",
      "                cmat[l, p] += 1\n",
      "                \n",
      "                k += 1\n",
      "        \n",
      "    return cmat\n",
      "\n",
      "from ffvideo import VideoStream\n",
      "def saveFrameTo(self, videoPath, frameNo, filePath, frameMode='L'):\n",
      "    import scipy\n",
      "    frames = []\n",
      "    self.vs = VideoStream(videoPath, frame_mode=frameMode)      \n",
      "    for i in range(-1,2):\n",
      "        try:\n",
      "            frames += [np.rot90(self.vs.get_frame_no(frameNo + i).ndarray())]\n",
      "        except:\n",
      "            pass\n",
      "        \n",
      "    frame = np.concatenate(tuple(frames), axis=1)    \n",
      "    scipy.misc.imsave(filePath, frame)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import grid_search\n",
      "\n",
      "c = RandomForestClassifier(n_jobs=6, n_estimators=160, max_depth=60)\n",
      "\n",
      "nonMilFeat =  [[i[10:-10] for i in feat[0]], feat[3]]\n",
      "\n",
      "cmat, predict, trainSet, testSet, selectionSet = crossValidateSectionSets(nonMilFeat, c,  Nfolds=10)\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 153   28]\n",
        " [ 116 9883]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Multiple instance learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## base line (traditional SVM)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm\n",
      "\n",
      "c = svm.SVC(kernel='r', C=30.0)#, max_iter=100)\n",
      "\n",
      "nonMilFeat =  [[i[10:-10] for i in feat[0]], feat[3]]\n",
      "\n",
      "cmat, predict, trainSet, testSet, selectionSet = crossValidateSectionSets(nonMilFeat, c,  Nfolds=10)\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:240: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 138   43]\n",
        " [ 532 9467]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## same svm with MIL"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import misvm\n",
      "\n",
      "c = misvm.MISVM(kernel='linear', C=100,gamma=0.0001, max_iters=50)\n",
      "# c = misvm.MISVM(kernel='linear', C=1.0, max_iters=50)\n",
      "# c = misvm.sMIL(kernel='linear', C=1.0), max_iters=50)\n",
      "\n",
      "noAddFeat = 10\n",
      "selClass = 2\n",
      "milFeat = [[extractPositiveInstances(f, 1000 - noAddFeat) for f in feat[selClass]], feat[3]]\n",
      "cmat, predict, trainSet, testSet, selectionSet = crossValidateSectionSetsMIL(milFeat, c, additionalFrames=noAddFeat, Nfolds=10)\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Non-random start..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-70-45c9cce8ad53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mselClass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmilFeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mextractPositiveInstances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnoAddFeat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselClass\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselectionSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrossValidateSectionSetsMIL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmilFeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madditionalFrames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoAddFeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNfolds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mcmat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-66-01394565295e>\u001b[0m in \u001b[0;36mcrossValidateSectionSetsMIL\u001b[1;34m(sets, classifier, additionalFrames, negativeSet, Nfolds, verbose)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;31m# train classifier and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mwclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mwclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLbl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mpredict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/peter/code/pyTools/pyToolsEnv/src/misvm/misvm/misvm.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, bags, y)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0msetup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintial_instances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mqp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIterativeQP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/peter/code/pyTools/pyToolsEnv/src/misvm/misvm/svm.py\u001b[0m in \u001b[0;36m_setup_svm\u001b[1;34m(self, examples, classes, C)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_smart_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/peter/code/pyTools/pyToolsEnv/src/misvm/misvm/svm.py\u001b[0m in \u001b[0;36m_smart_kernel\u001b[1;34m(kernel, examples)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/peter/code/pyTools/pyToolsEnv/src/misvm/misvm/kernel.py\u001b[0m in \u001b[0;36mK\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_kernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/peter/code/pyTools/pyToolsEnv/src/misvm/misvm/kernel.py\u001b[0m in \u001b[0;36mrbf_kernel\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;34m\"\"\"Radial Basis Function\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrbf_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sqeuclidean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrbf_kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/peter/code/pyTools/pyToolsEnv/lib/python2.7/site-packages/scipy/spatial/distance.pyc\u001b[0m in \u001b[0;36mcdist\u001b[1;34m(XA, XB, metric, p, V, VI, w)\u001b[0m\n\u001b[0;32m   2003\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmstr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sqeuclidean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sqe'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sqeuclid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m             _distance_wrap.cdist_euclidean_wrap(_convert_to_double(XA),\n\u001b[1;32m-> 2005\u001b[1;33m                                                 _convert_to_double(XB), dm)\n\u001b[0m\u001b[0;32m   2006\u001b[0m             \u001b[0mdm\u001b[0m \u001b[1;33m**=\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmstr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cityblock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cblock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Extensive grid-search over different MIL approaches"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import misvm as ms\n",
      "\n",
      "# make deque to list\n",
      "aSList = [[list(b) for b in a] for a in aS]\n",
      "\n",
      "# ensure int everywhere\n",
      "aSList = [[[[c[0], int(c[1]), c[2]] for c in b] for b in a] for a in aSList]\n",
      "\n",
      "with open('aS.json', 'w') as f:\n",
      "    json.dump(aSList, f)\n",
      "    \n",
      "MISVM = {'classifier':ms.MISVM, 'kernel':['linear'], 'C':[0.1, 1.0, 10.0, 100.0, 1000.0], 'gamma':[1**(-3), 1**(-2),1**(-1), 1**0, 1**2, 1**3]}\n",
      "sMIL = {'classifier':ms.sMIL, 'kernel':['linear'], 'C':[0.1, 1.0, 10.0, 100.0, 1000.0], 'gamma':[1**(-3), 1**(-2),1**(-1), 1**0, 1**2, 1**3]}\n",
      "sbMIL = {'classifier':ms.sbMIL, 'kernel':['linear'], 'C':[0.1, 1.0, 10.0, 100.0, 1000.0], 'gamma':[1**(-3), 1**(-2),1**(-1), 1**0, 1**2, 1**3]}\n",
      "stMIL = {'classifier':ms.stMIL, 'kernel':['linear'], 'C':[0.1, 1.0, 10.0, 100.0, 1000.0], 'gamma':[1**(-3), 1**(-2),1**(-1), 1**0, 1**2, 1**3]}\n",
      "\n",
      "classifiers = [MISVM, sMIL, sbMIL, stMIL]\n",
      "classSets = [[0,3],\n",
      "             [1,3],\n",
      "             [2,3]]\n",
      "\n",
      "\n",
      "noAddFeat = [10, 100, 500, 1000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for addFeat in noAddFeat:\n",
      "    for cfr in classifiers:\n",
      "        for k in cfr['kernel']:\n",
      "            for c in cfr['C']:\n",
      "                for gamma in cfr['gamma']:\n",
      "                    print(\"computing {0} with {1} kernel and C={2} and gamma={3} using {4} additional negative instances\".format(cfr, k, c, gamma, addFeat))                \n",
      "                    classifier = cfr(kernel=k, C=c, gamma=gamma, verbose=False)\n",
      "                    for cs in classSet:\n",
      "                        print(\"training for class {0}\".format(cs)\n",
      "                        milFeat = [[extractPositiveInstances(f, 1000 - addFeat) for f in feat[cs[0]]], feat[cs[1]]]\n",
      "                        t = time.time()\n",
      "                        cmat, predict, trainSet, testSet, selectionSet = crossValidateSectionSetsMIL(milFeat, classifier, additionalFrames=addFeat, Nfolds=10)\n",
      "                        runningTime = time.time() - t\n",
      "                        result = {'cmat':cmat.tolist(), 'predict': [p.tolist() for p in predict],\n",
      "                                  'trainSet': [t.tolist() for t in trainSet],\n",
      "                                  'testSet': [t.tolist() for t in testSet],\n",
      "                                  'selectionSet': [[[c.tolist()] for c in s] for s in selectionSet],\n",
      "                                  'runningTime': runningTime,\n",
      "                                  'kernel':k, 'C':c, 'gamma':gamma, 'classifier':str(classifier)}\n",
      "                        \n",
      "                        acc = int(np.sum(cmat.diagonal()) / np.sum(cmat.flatten()))\n",
      "                        fn = 'results/{classifier} - {kernel} - C{C} - g{g} - acc {acc} - time {time}.json'.format(\\\n",
      "                                classifier=classifier, kernel=kernel, C=c, g=gamma, acc=acc, time=runningTime)\n",
      "                        with open(fn, 'w') as f:\n",
      "                            json.dump(result, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = {'cmat':cmat.tolist(), 'predict': [p.tolist() for p in predict],\n",
      "          'trainSet': [t.tolist() for t in trainSet],\n",
      "          'testSet': [t.tolist() for t in testSet],\n",
      "          'selectionSet': [[[c.tolist()] for c in s] for s in selectionSet],\n",
      "          'runningTime': runningTime,\n",
      "          'kernel':k, 'C':c, 'gamma':gamma, 'classifier':str(classifier)}\n",
      "\n",
      "with open('result.json', 'w') as f:\n",
      "    json.dump(result, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flatSect = flattenAnnotationSections(sect)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 326
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat[0][0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "(4, 314)"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[len(a) for a in flatSect]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 327,
       "text": [
        "[52, 1384, 78]"
       ]
      }
     ],
     "prompt_number": 327
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "# ending = ['feat.hog3d', 'feat.hog3d-xy2-t0.5', 'feat.hog3d-xy1-t0.25', 'feat.hog3d-xy2-t0.25', 'feat.hog-8', 'feat.pos']\n",
      "ending = ['feat.hog3d', 'feat.pos']\n",
      "# ending = ['feat.hog3d-xy2-t0.5']\n",
      "featS = createFeatureVector(aF[0], ending=ending)\n",
      "featF = createFeatureVector(aF[1], ending=ending)\n",
      "featD = createFeatureVector(aF[2], ending=ending)\n",
      "cfg.log.info(\"finished in {0} sec\".format(time.time() - t)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\u001b[41mINFO\u001b[49m \u001b[1m2013-09-23 20:02:24,603 \u001b[0m[T: 140402299045696] \u001b[33m<<module>> \u001b[39m[8] \u001b[1mfinished in 12.1003558636 sec\u001b[0m\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:log:finished in 12.1003558636 sec\n"
       ]
      }
     ],
     "prompt_number": 361
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat =[featS, featF, featD]\n",
      "labels = [[0] * featS.shape[0], [1] * featF.shape[0], [2] * featD.shape[0]]\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import grid_search\n",
      "\n",
      "c = RandomForestClassifier(n_jobs=6, n_estimators=100, max_depth=50)\n",
      "\n",
      "cmat, predict, trainSets, testSets = crossValidateSampleSets(feat, labels, flatSect, c,  Nfolds=10)\n",
      "\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:130: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  126    48     7]\n",
        " [  318  4214   116]\n",
        " [  279    87 10033]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aF[0][0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 285,
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130219/00/2013-02-19.00-06-00.bhvr',\n",
        " 1600,\n",
        " 0]"
       ]
      }
     ],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flattenedAF = flattenAnnotatedFrames(aF)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 330
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saveConfusionMatrix(predict, testSet, aS)   \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "array([[  1.26000000e+02,   3.00000000e+01,   2.00000000e+00,\n",
        "          2.30000000e+01],\n",
        "       [  3.00000000e+02,   4.18400000e+03,   8.40000000e+01,\n",
        "          8.00000000e+01],\n",
        "       [  1.97000000e+02,   6.70000000e+01,   9.84100000e+03,\n",
        "          2.94000000e+02],\n",
        "       [  1.90000000e+01,   2.35000000e+02,   4.33000000e+02,\n",
        "          9.31000000e+03]])"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flattenedAF[0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 333,
       "text": [
        "['/run/media/peter/Elements/peter/data/tmp-20130506/20130219/00/2013-02-19.00-06-00.bhvr',\n",
        " 1597,\n",
        " 0]"
       ]
      }
     ],
     "prompt_number": 333
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(testSets)):\n",
      "    saveConfusionMatrix(predict[i], testSets[i], flattenedAF)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 360
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.arange(9).reshape((3,3))\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 1 2]\n",
        " [3 4 5]\n",
        " [6 7 8]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 344
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.rot90(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 346,
       "text": [
        "array([[2, 5, 8],\n",
        "       [1, 4, 7],\n",
        "       [0, 3, 6]])"
       ]
      }
     ],
     "prompt_number": 346
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rngS = np.random.permutation(range(featS.shape[0]))[:181]\n",
      "# rngD = np.random.permutation(range(featD.shape[0]))[:181]\n",
      "\n",
      "feat = np.concatenate(tuple([\\\n",
      "                            featS,\n",
      "                            featF,\n",
      "                            featD]))\n",
      "\n",
      "labels = np.concatenate(tuple([\\\n",
      "                              [0] * featS.shape[0],\n",
      "                              [1] * featF.shape[0],\n",
      "                              [2] * featD.shape[0]]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import grid_search\n",
      "\n",
      "c = RandomForestClassifier(n_jobs=6, criterion='entropy')\n",
      "# c = RandomForestClassifier(n_estimators=50, max_depth=30, n_jobs=6)\n",
      "\n",
      "parameters = {'n_estimators':[1,5,10,20,50,70,100,125,150,175,200,225], 'max_depth':[1, 10,20,30,40,50,60,70,80,90]}\n",
      "\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "\n",
      "clf = grid_search.GridSearchCV(c, parameters)\n",
      "clf.fit(feat, labels)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='entropy', max_depth=None, max_features='auto',\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=10, n_jobs=6, oob_score=False, random_state=None,\n",
        "            verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_estimators': [1, 5, 10, 20, 50, 70, 100, 125, 150, 175, 200, 225], 'max_depth': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='entropy', max_depth=90, max_features='auto',\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=150, n_jobs=6, oob_score=False, random_state=None,\n",
        "            verbose=0)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "c = RandomForestClassifier(n_estimators=150, max_depth=90, n_jobs=6, criterion='gini')\n",
      "\n",
      "\n",
      "cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[173   8   0]\n",
        " [  1 174   6]\n",
        " [  6  13 162]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# c.fit(feat, labels)\n",
      "\n",
      "rngST = list(set(range(featS.shape[0])).difference(rngS))\n",
      "rngDT = list(set(range(featD.shape[0])).difference(rngD))\n",
      "    \n",
      "featT = np.concatenate(tuple([\\\n",
      "                            featS[rngST],\n",
      "                            featD[rngDT]]))\n",
      "\n",
      "labelsT = np.concatenate(tuple([\\\n",
      "                              [0] * len(rngST),\n",
      "                              [2] * len(rngDT)]))\n",
      "\n",
      "plabels = c.predict(featT)\n",
      "computeConfusionMatrix(plabels, labelsT)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "array([[ 9843.,   282.,    93.],\n",
        "       [    0.,     0.,     0.],\n",
        "       [  129.,   376.,  3962.]])"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances = c.feature_importances_\n",
      "std = np.std([tree.feature_importances_ for tree in c.estimators_],\n",
      "             axis=0)\n",
      "indices = np.argsort(importances)[::-1][:10]\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(10):\n",
      "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
      "\n",
      "# Plot the feature importances of the forest\n",
      "import pylab as pl\n",
      "pl.figure()\n",
      "pl.title(\"Feature importances\")\n",
      "pl.bar(range(10), importances[indices],\n",
      "       color=\"r\", yerr=std[indices], align=\"center\")\n",
      "pl.xticks(range(10), indices)\n",
      "pl.xlim([-1, 10])\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature ranking:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1. feature 325 (0.018451)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2. feature 620 (0.017953)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3. feature 17 (0.015485)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4. feature 1010 (0.014643)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5. feature 781 (0.014251)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6. feature 356 (0.014045)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7. feature 340 (0.010098)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8. feature 1023 (0.009829)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9. feature 33 (0.009811)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10. feature 151 (0.009515)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.argsort(importances)[::-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([325, 620,  17, ...,   0, 116, 321])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn import svm\n",
      "\n",
      "\n",
      "# c = svm.SVC()\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, c,  Nfolds=10)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.ensemble import AdaBoostClassifier\n",
      "# from sklearn import svm\n",
      "# from sklearn.linear_model import SGDClassifier\n",
      "# from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "# base = c#MultinomialNB()\n",
      "# ada = AdaBoostClassifier(base_estimator=base)\n",
      "# cmat, predict, testLbl, testPos = crossValidate(feat, labels, ada,  Nfolds=10)\n",
      "\n",
      "# print cmat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 1/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 2/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 3/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 4/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 5/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 6/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 7/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 8/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 9/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing fold no 10/10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:38: DeprecationWarning: Implicitly casting between incompatible kinds. In a future numpy release, this will raise an error. Use casting=\"unsafe\" if this is intentional.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[10359     2    38]\n",
        " [   30    55    96]\n",
        " [   86     0  4562]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = set(range(featS.shape[0])).difference(rngS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "10218"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featS.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "10399"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%qtconsole"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = time.localtime()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.tmm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}